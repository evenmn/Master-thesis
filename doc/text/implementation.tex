\chapter{Implementation} \label{sec:implementation}
\epigraph{There are only two hard things in Computer Science: cache invalidation and naming things.}{Phil Karlton, \cite{fowler_bliki:_nodate}}
\iffalse
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{Images/example.png}
	\caption{Caption}
\end{figure}
\fi

In this chapter de will describe the implemented VMC code, which was developed from scratch in C++. As the code itself is around 7000 significant\footnote{Significant lines of code in this sense means lines that are not blank or commented. Counted by the cloc program \cite{aldanial_cloc_2019}.} lines of code, we will just go through selected and often not obvious parts. As often said, \textit{good planning is half the battle}, which largely relates to writing VMC code. The code was rewritten and restructured several times before we ended on the final version. As a starting point, we used Morten Ledum's VMC framework \cite{ledum_simple_2016}, which was meant as an example implementation in the course \textit{FYS4411 - Computational Physics II: Quantum Mechanical Systems}. The entire source code can be found on the authors github, \cite{nordhagen_general_2019}.

For all matrix operations, the open source template library for linear algebra Eigen was used throughout the code. Eigen provides an elegant interface, with support for all the needed matrix and vector operations. In addition, Eigen is built on the standard software libraries for numerical linear algebra, BLAS and LAPACK, which are incredibly fast. These contribute greatly to the performance of the code. 

The code was developed in regards to three principal aims:
\begin{center}
	\begin{minipage}{0.2\textwidth}
		\begin{itemize}
			%\itemsep-0.6em
			\item flexible,
			\item fast,
			\item readable.
		\end{itemize}
	\end{minipage}
\end{center}
It needs to be flexible in order to support the Boltzmann machines as our trial wave function guess, and since we will try out various Jastrow factors it should be easy to add and remove wave function elements. Since quantum mechanical simulations in general are very expensive, it is important to develop efficient code to be able to study systems of some size. Lastly, we aim to write readable code such that others can reuse the code in its entirety or parts of it later. 

How we work to achieve the goals will be illustrated by code mainly picked from the \lstinline{WaveFunction} class, which is the heart of the code. 

\section{Flexibility}
Unlike many other VMC codes, our code was developed flexible with respect to the wave functions. This means that one can combine various wave function elements, where each element is implemented separately. For instance, the Slater determinant with the Gaussian part factorized out and the Padé-Jastrow factor were implemented as three separate elements, but they all can easily be combined. The way one does this in practice, is to append the wave function elements to a vector \lstinline{waveFunctionElements}. A trial wave function for a quantum dot combining a Slater determinant with the Gaussian part factorized out and the Padé-Jastrow factor can be specified by a system \lstinline{quantumDot} is the following way

\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language=c++,caption={The code was implemented in a flexible way such that all the wave function elements can be combined with other wave function elements by appending all the wanted elements to a vector, here named \lstinline{waveFunctionElements}, which again is set as the trial wave function using the function \lstinline{setWaveFunctionElements}.}]
System* quantumDot = new System();
std::vector<class WaveFunction*> waveFunctionElements;

waveFunctionElements.push_back(new Gaussian(quantumDot));
waveFunctionElements.push_back(new PadeJastrow(quantumDot));
waveFunctionElements.push_back(new SlaterDeterminant(quantumDot));

quantumDot->setWaveFunctionElements(WaveFunctionElements);
\end{lstlisting}

The big advantage of this implementation technique is that we do not need to hard code every possible combination of wave function elements, which reduces the number of code lines significantly. This will be very useful when dealing with the Boltzmann machines, which will be tested with various Jastrow factors, and also with extensions like the partly restricted element. Additionally, this also eases the operation of adding new elements, since we only need to calculate the derivatives of the particular element (do not need to worry about cross terms). The exact derivation of all the wave function elements, with all the required derivatives, can be read in chapter \ref{chp:WFE}. The con is that the program becomes slightly slower, since even canceling cross terms are calculated, but it will most likely not be noticeable. In the next section, we will look at what really matters when dealing with the efficiency of the code.

\section{Efficiency}
Even though the computers have become much faster the past decades, they are still far from being fast enough for large scale quantum computations. To be able to study interesting systems, which often are relatively large, we therefore need to focus on the efficiency in all terms. In our particular code, a majority of the run time is spent on the sampling such that this is the part we should aim to optimize. For profiling, we used \textbf{callgrind} with \textbf{kcachegrind} visualization, which are great tools when we want to where we waste CPU time. 

In general, there are several points that one should consider when optimizing the code, including
\begin{itemize}
	%\itemsep-0.6em
	\item finding closed-form expressions if possible,
	\item never repeat calculations,
	\item express the update of variables iteratively.
\end{itemize}
We have already done the first point for all our wave function elements. The explicit expressions are presented in chapter \ref{chp:WFE}, where we also write about possible optimization schemes for each specific wave function element. In the next section, \ref{sec:thewavefunctionclass}, we will go through how the wave function class is implemented with respect to the optimizations.

Furthermore, we will describe how the distance matrix is updated in section \ref{sec:distancematrix}, which is an illustrating example on how to avoid repeating calculations. This might sounds obvious, but in complex calculations not recalculate anything is really an art. 

Lastly, we will show how vectors and matrices can be updated iteratively to gain efficiency. We do this in more or less all the wave function elements, but as the update of the Slater determinant is the most comprehensive, we will pick parts of it as examples, given in section \ref{sec:updateslater}. However, we will first look at the wave function class. 

\subsection{The wave function class} \label{sec:thewavefunctionclass}
The wave function class is the heart of the code, and in order to make the code fast, it needs to be implemented in a clever way. In chapter \ref{chp:scientificprogramming}, we reviewed how virtual functions can be used to force all the sub-classes of a class to have the same properties, which we will utilize here. Each wave function element should at least carry the properties \lstinline{evaluateRatio} (which returns the probability ratio), \lstinline{computeGradient} (which returns $\nabla_k\ln\psi_i(\bs{r})$), \lstinline{computeLaplacian} (which returns $\nabla^2\ln\psi_i(\bs{r})$) and \lstinline{computeParameterGradient} (which returns $\partial_{\theta}\ln\psi_i(\bs{r})$). All these four expressions are given in chapter \ref{chp:WFE} for all the wave function elements. In addition, the wave function class includes a bunch of functions that are used in the update of vectors, parameters and so on. We will first present the virtual functions in the header file \lstinline{wavefunction.h}, and thereafter discuss how the various functions are used in the optimization. The public part of the header reads
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language=c++,caption={The code is taken from \lstinline{wavefunction.h}, presenting all the virtual functions that are used in the wave function class. Clang formating is used.}]
public:
	WaveFunction(class System *system);
	virtual int getNumberOfParameters() = 0;
	virtual int getGlobalArrayNeed() = 0;
	virtual std::string getLabel() = 0;

	virtual void updateParameters(const Eigen::MatrixXd parameters) = 0;
	virtual void initializeArrays(const Eigen::VectorXd positions,
								  const Eigen::VectorXd radialVector,
								  const Eigen::MatrixXd distanceMatrix)
		= 0;
	virtual void updateArrays(const Eigen::VectorXd positions,
							  const Eigen::VectorXd radialVector,
							  const Eigen::MatrixXd distanceMatrix,
							  const int changedCoord)
		= 0;
	virtual void setConstants(const int elementNumber) = 0;
	virtual void setArrays() = 0;
	virtual void resetArrays() = 0;
	virtual double evaluateRatio() = 0;
	virtual double computeGradient(const int k) = 0;
	virtual double computeLaplacian() = 0;
	virtual Eigen::VectorXd computeParameterGradient() = 0;

	virtual ~WaveFunction() = 0;

\end{lstlisting}

The three former functions are returning the properties "number of parameters", "array need" and "label" respectively for each wave function element. The first one, \lstinline{getNumberOfParameters}, is important when declaring the global parameter matrix, which contains all the parameters in all the elements. The \lstinline{getGlobalArrayNeed} function is used to chart the need of the distance matrix, containing all the relative distances, and the radial vector, containing all the radial coordinates, $r_i=\sqrt{x_i^2+y_i^2+z_i^2}$. An element returns 1 if it requires the distance matrix, 2 if it requires the radial vector, 3 if it requires both and 0 if it requires none. This makes it possible to calculate the global arrays only when they are needed. The \lstinline{getLabel} function is returning the label of the respective element, used to collect a composition of elements under a common label (ex. "RBM" contains the elements "slaterdeterminant", "rbmgaussian" and "rbmproduct").

Further, the \lstinline{updateParameters} is called to update the parameters in each wave function element after the global parameter matrix is updated. \lstinline{initializeArrays} is used to initialize all the arrays in an element, which is important when the arrays are updated iteratively, since the first update then is unique. This function will therefore only be called in the very beginning of a run. After this, all the arrays are updated using the \lstinline{updateArrays} function, where all the iterative magic happens, further detailed in section \ref{sec:updateslater}. As this function takes the changed coordinate, \lstinline{changedCoord}, as argument, it can update only the affected parts of the arrays. 

We always need to store the old arrays in case a move is rejected, since we then need to go back to the old state. The function \lstinline{setArrays} replaces the old arrays with the new arrays, $\bs{X}_{\text{old}}=\bs{X}_{\text{new}}$, which is done to store the arrays. When a move is rejected, we need to reset the arrays going the other way, $\bs{X}_{\text{new}}=\bs{X}_{\text{old}}$, which naturally is done by the function \lstinline{resetArrays}. Finally, the function \lstinline{setConstants} is called once, and gives each element a unique element number and defines the size of the global parameter matrix. 

Before we proceed further, we will give an example from the code on how a specific element is implemented. For simplicity, we choose the simple Gaussian found in \lstinline{gaussian.cpp} and detailed in section \ref{sec:simplegaussian}. As the mathematical form is
\begin{equation}
\psi(\bs{r};\alpha)=\exp(-\frac{1}{2}\alpha\omega|\bs{r}|^2)
\end{equation}
we can apply the radial vector to evaluate the function (this is not strictly necessary, but serves as a good example). Since this element then requires the radial vector, we need to set \lstinline{int globalArrayNeed=2}. We initialize the arrays by implementing the function \lstinline{initializeArrays} in the following way
\begin{lstlisting}[language=c++,caption={Initialization of arrays, taken from \lstinline{gaussian.cpp}.}]
void Gaussian::initializeArrays(const Eigen::VectorXd positions,
								const Eigen::VectorXd radialVector,
								const Eigen::MatrixXd distanceMatrix)
{
	m_positions = positions;
	m_radialVector = radialVector;
	m_probabilityRatio = 1;
}
\end{lstlisting}
where we initially set the probability ratio, $p(\bs{r}',\bs{r})=|\psi(\bs{r}')|^2/|\psi(\bs{r})|^2$. What is more interesting, is how the closed-form expression of the updated probability ratio, derived in section \ref{sec:simplegaussian}, is implemented. This is performed by using the non-virtual function \lstinline{updateProbabilityRatio} which again is called from the virtual function \lstinline{updateArrays}. The former reads
\begin{lstlisting}[language=c++,caption={Update of probability ratio, taken from \lstinline{gaussian.cpp}.}]
void Gaussian::updateProbabilityRatio(int changedCoord)
{
	m_probabilityRatio = exp(m_omega * m_alpha
		* (m_radialVectorOld(changedCoord) * m_radialVectorOld(changedCoord)
		   - m_radialVector(changedCoord) * m_radialVector(changedCoord)));
}
\end{lstlisting}
where we recognize the ratio presented in equation \eqref{eq:simplegaussianprobabilityratio}. Further, the radial vector is updated globally similarly to the distance matrix, which we will look at in the next section. The \lstinline{setArrays} function is simply implemented as
\begin{lstlisting}[language=c++,caption={Replacing old arrays with the new arrays, taken from \lstinline{gaussian.cpp}.}]
void Gaussian::setArrays()
{
	m_positionsOld = m_positions;
	m_probabilityRatioOld = m_probabilityRatio;
	m_radialVectorOld = m_radialVector;
}
\end{lstlisting}
and the \lstinline{resetArrays} function is similarly given by
\begin{lstlisting}[language=c++,caption={Replacing new arrays with the old arrays, taken from \lstinline{gaussian.cpp}.}]
void Gaussian::resetArrays()
{
	m_positions = m_positionsOld;
	m_probabilityRatio = m_probabilityRatioOld;
	m_radialVector = m_radialVectorOld;
}
\end{lstlisting}
this finalizes our minimalistic demonstration of how the the closed-form expressions are used in the code, but in section \ref{sec:updateslater}, the implementation of the Slater determinant is taken under the magnifying glass. Before that, we will show how we can update certain elements of an array instead of updating all the elements to save computational time, with the distance matrix as an example.

\subsection{Updating the distance matrix} \label{sec:distancematrix}
The distance matrix, which is used in the Jastrow factors, gives an illustrating example how we can avoid repeating calculations. The matrix, henceforth named $M$, contains the relative distances between all the particles, for three particles given by
\begin{eqnarray}
M=
\begin{pmatrix}
r_{11} & r_{12} & r_{13} \\
r_{21} & r_{22} & r_{23} \\
r_{31} & r_{32} & r_{33}
\end{pmatrix}
=
\begin{pmatrix}
0 & r_{12} & r_{13} \\
r_{12} & 0 & r_{23} \\
r_{13} & r_{23} & 0
\end{pmatrix}
\end{eqnarray}
where $r_{ij}$ means the distance between particles $i$ and $j$. Since $r_{ij}=r_{ji}$ and $r_{ii}=0$, the matrix becomes symmetric with zeros on the diagonal, which means that we only need to calculate $N(N-1)/2$ elements instead of $N^2$. Further, we can exploit that only a particle is moved at a time, which means that only a row and a column are changed when a particle is moved. For instance, if particle 1 is moved, the upper row and the left-hand-side column in matrix $M$ need to be updated. In our program, we have implemented this in the following way
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language=c++,caption={When a particle is moved, we update a row and a column in the distance matrix. The functions are parts of the Metropolis class, as the distance matrix is updated for every step in the Metropolis sampling. Taken from \lstinline{metropolis.cpp}.}]
double Metropolis::calculateDistanceMatrixElement(const int i, const int j) {
	double dist = 0;
	int parti   = m_numberOfDimensions*i;
	int partj   = m_numberOfDimensions*j;
	for(int d=0; d<m_numberOfDimensions; d++) {
		double diff = m_positions(parti+d)-m_positions(partj+d);
		dist += diff*diff;
	}
	return sqrt(dist);
}

void Metropolis::calculateDistanceMatrixCross(const int particle) {
	for(int i=0; i<m_numberOfParticles; i++) {
		m_distanceMatrix(particle, i) = calculateDistanceMatrixElement(particle, i);
		m_distanceMatrix(i, particle) = m_distanceMatrix(particle, i);
	}
}
\end{lstlisting}
where the function \lstinline{calculateDistanceMatrixElement(i,j)} returns element \lstinline{i,j} of the matrix, which is called from the function \lstinline{calculateDistanceMatrixCross(particle)}. The latter takes the moved particle index as input, and updates the necessary row and column of the matrix. 

For systems of non-interacting particles, the distance matrix is redundant, and should therefore not be calculated. We have solved this by giving all the wave function elements and the Hamiltonians a number which indicated whether they require the distance matrix or not, as mentioned above. If no part of the code needs the distance matrix, it is never calculated. 

We also calculate the radial position, when it is required by any part of the code. The components are stored in a vector named \lstinline{radialVector}, applying the same optimization ideas as the distance matrix. 

\subsection{Recursive update of the Slater determinant} \label{sec:updateslater}
In this section, we will explain how the code can be speed-up using recursive relations between the old and the new array, instead of updating the array from scratch every time. We will use the Slater determinant as an example, as this element requires the computation of the inverse of a matrix, which can be performed by iterative operations. As pointed out in an earlier section, inverting a matrix using the standard LU decomposition scales as $\sim\mathcal{O}(N^3)$ for a $N\times N$ matrix, which quickly becomes impossible to evaluate. 

The theory behind this update is in the entirety given in section \ref{sec:efficientcalculationsofslaterdeterminant}. We can also present the update of the Slater determinant on algorithm form
\begin{enumerate}
	\item Update all elements $d_{ji}$ in the Slater matrix using the fact that only the elements $d_{jk}$ are updated when particle $k$ is moved (row $j$ in the Slater matrix).
	\item Update all the elements $\nabla_kd_{ji}=\nabla_kd_{jk}$ in the Slater-derivative matrix, which stores the derivative of all the elements in the Slater matrix with respect to all coordinates.
	\item Update all the elements $\nabla_kd_{ji}=\nabla_kd_{jk}$ in the Slater-derivative matrix, which stores the derivative of all the elements in the Slater matrix with respect to all coordinates.
\end{enumerate}


\section{Readability}
Whenever writing code, the code should be not only be understandable for the computer, but also for humans. We naively let ClangFormat format our code, since this is known to be readable. 

To maximize the readability, we developed a highly object oriented code based on the theory in chapter \eqref{chp:scientificprogramming}. For instance, each wave function element was treated as an object, with the properties \lstinline{updateArrays}, \lstinline{setArrays}, \lstinline{resetArrays}, \lstinline{initializeArrays}, \lstinline{updateParameters}, \lstinline{evaluateRatio}, \lstinline{computeGradient}, \lstinline{computeLaplacian} and \newline\lstinline{computeParameterGradient}. To ensure that all wave function elements have all the necessary properties, the super class \lstinline{WaveFunctions} is equipped with the corresponding virtual functions
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language=c++,caption={\lstinline{wavefunction.h}}]
#pragma once
#include <Eigen/Dense>
#include <iostream>

class WaveFunction {
public:
WaveFunction(class System *system);
virtual void   updateArrays    (Eigen::VectorXd positions, int pRand)  = 0;
virtual void   setArrays       () = 0;
virtual void   resetArrays     () = 0;
virtual void   initializeArrays(Eigen::VectorXd positions) = 0;
virtual void   updateParameters(Eigen::MatrixXd parameters, int elementNumber) = 0;

virtual double evaluateRatio   ()      = 0;
virtual double computeGradient (int k) = 0;
virtual double computeLaplacian()      = 0;

virtual Eigen::VectorXd computeParameterGradient() = 0;

virtual ~WaveFunction() = 0;

protected:
int     m_numberOfParticles                 = 0;
int     m_numberOfDimensions                = 0;
int     m_numberOfFreeDimensions            = 0;
int     m_maxNumberOfParametersPerElement   = 0;
class System* m_system = nullptr;
};
\end{lstlisting}
which serves a template for all the sub classes (wave function elements). As you might notice, we use the \textbf{lowerCamelCase} naming convention for function and variable names, which means that each word begins with a capital letter except the initial word. For classes, we use the \textbf{UpperCamelCase} to distinguish from function names. This is known to be easy to read, and apart from for example the popular \textbf{snake\_case}, we do not need delimiters between the words, which saves some space. After the naming convention is decided, we are still responsible for giving reasonable names, which is not always an easy task, as Phil Karlton points out. When one sees the name, one should know exactly what the variable/function/class is or does. More about naming conventions can be read at Ref.\cite{noauthor_naming_2019}.

\subsection{Energy calculation}
The way we calculate the total kinetic energy then is based on the theory presented in chapter \ref{chp:WFE}, where we explain that
\begin{equation}
T=-\frac{1}{2}\frac{1}{\Psi_T}\nabla_k^2\Psi_T=-\frac{1}{2}\bigg[\sum_{i=1}^p\nabla_k^2\ln\phi_i + \Big(\sum_{i=1}^p\nabla_k\ln\phi_i\Big)^2\bigg].
\end{equation}
The corresponding implementation thus reads
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language=c++,caption={from \lstinline{system.cpp}}]
double System::getKineticEnergy() {
    double kineticEnergy = 0;
    for(auto& i : m_waveFunctionElements) {
        kineticEnergy += i->computeLaplacian();
    }
    for(int k = 0; k < m_numberOfFreeDimensions; k++) {
        double nablaLnPsi = 0;
        for(auto& i : m_waveFunctionElements) {
            nablaLnPsi += i->computeGradient(k);
        }
        kineticEnergy += nablaLnPsi * nablaLnPsi;
    }
    return - 0.5 * kineticEnergy;
}
\end{lstlisting}

\subsection{Probability ratio calculation}
In the same chapter we state the obvious fact that 
\begin{equation*}
	\frac{\Psi_T^{\text{new}}}{\Psi_T^{\text{old}}}=\prod_{i=1}^p\frac{\phi_i^{\text{new}}}{\phi_i^{\text{old}}},
\end{equation*}
which can easily be implemented as
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language=c++,caption={from \lstinline{system.cpp}}]
double System::evaluateWaveFunctionRatio() {
    double ratio = 1;
    for(auto& i : m_waveFunctionElements) {
        ratio *= i->evaluateRatio();
    }
    return ratio;
}
\end{lstlisting}

\subsection{Parameters}
Another consequence of this flexible implementation is that we need to treat all parameters in the same way to make everything general. To do this, we create a global matrix of dimensions $n \cross m$ where $n$ is the number of wave function elements and $m$ is the maximum number of parameters in a wave function element. Thus each element has its own row in the matrix, and one can easily track down a specific parameter. 

For the parameter update, each element needs to provide an array of length $m$ containing its respective parameter gradients. This array is calculated in the function \newline \lstinline{computeParameterGradient} for each element, and they are all collected in the function \lstinline{getAllInstantGradients}:

\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language=c++,caption={from \lstinline{system.cpp}}]
Eigen::MatrixXd System::getAllInstantGradients() {
    Eigen::MatrixXd gradients = Eigen::MatrixXd::Zero(m_numberOfWaveFunctionElements, \
    m_maxNumberOfParametersPerElement);
    for(int i = 0; i < m_numberOfWaveFunctionElements; i++) {
        gradients.row(i) = m_waveFunctionElements[i]->computeParameterGradient();
    }
    return gradients;
}
\end{lstlisting}
We need to stress that those are the instant gradients calculated every time a particle is moved. Exactly how the parameters are updated depends on an average of these, described in chapter \ref{chp:WFE}. 

Immediately after the parameters are updated, the new parameters need to be sent into the wave function elements. This is done through the functions \lstinline{updateParameters}, which update all the parameters and weights in the elements. In addition, the function has the responsibility to order the elements such that none gets the same number. 


\section{Structure} \label{subsec:structure}
How the classes are communicating is no easy task to explain, most classes are calling other classes, there is no tidy way to visualize the actual code flow. However, a simplified structure chart can still be informative, and in figure \eqref{fig:structurechart} the most important calls between the different classes are pointed out. We decided to leave out \lstinline{main.cpp} since all it does is to set the different classes. 

\begin{figure} [h]
	\centering
	\label{fig:structurechart}
	\input{tikz/program_structure.tex}
	\caption{Structure chart of the implemented code, presenting super classes as tiles. The most important intra-class calls are represented with lines pointing from the sender class towards the receiver class.}
\end{figure}

This is the main aim of the flow, but the actual flow does also depend on system. For instance, when using importance sampling, we will have an additional call between \lstinline{WaveFunctions} and \lstinline{Metropolis} due to calculations of the quantum force. 

\section{Random number generators} \label{sec:RNG}
In the Monte-Carlo sampling we are drawing millions of numbers, and in order to get accurate estimations, they should all be random, independent and fast to get. 

In C++ there are plenty of random number generator available, but not all of them meet our requirements. For instance the standard 

Mersenne Twister needs to be mentioned here

\iffalse
\section{Foundation} \label{subsec:foundation}
The foundation of the code are all the super classes, nine in the number. They all have multiple sub classes, and the reader needs to specify which sub class to be used. The exception is the \lstinline{WaveFunctions} class, as described above, where multiple sub classes can be used. Below, the role of all the super classes will be discussed briefly and the difference between various sub classes will be explained. 

\subsection{Super classes}

\subsubsection{The \lstinline{Basis} class}
In this class, one needs to choose which basis set that should be used in the Slater determinant. There are three required functions:
\begin{itemize}
	\item \lstinline{numberOfOrbitals()} gives the number of orbitals given the number of particles and dimensions. This is used in the Slater determinant.
	
	\item \lstinline{evaluate(double x, int n)} gives the the value of element \lstinline{n} for a given \lstinline{x}. 
	
	\item \lstinline{evaluateDerivative(double x, int n)} gives the derivative of element \lstinline{n} with respect to \lstinline{x} for a given \lstinline{x}.  
\end{itemize}

Possible sub classes choices are \lstinline{Hermite} and \lstinline{HydrogenLike}, where the former is well-suited for quantum dots and the latter is used in atomic structure calculations. 

\subsubsection{The \lstinline{Hamiltonians} class}
In this class, one needs to specify the Hamiltonian of the system. The only required function is \lstinline{computeLocalEnergy()}, which returns the local energy. One can choose between the Hamiltonians \lstinline{AtomicNucleus} and \lstinline{HarmonicOscillator}, where the first one sets up an external potential like the one we find in an atom, and takes the atomic number $Z$ as an argument. The second one sets up a harmonic oscillator potential, and actually the only thing that distinguish the who classes is the external energy calculation. 

\subsubsection{The \lstinline{InitialStates} class}
In one way or another we need to initialize the particle positions, but how we want to do this depends on the situation. The implemented methods are randomly initialized positions drawn from a uniform or normal distribution, \lstinline{RandomUniform} and \lstinline{RandomNormal} respectively. They consist of the function \lstinline{setupInitialState()}.

\subsubsection{The \lstinline{InitialWeights} class}
In the same manner as the \lstinline{InitialStates} class, we can initialize the weights in various ways. One way is to set all the weights to the same initial value, represented by the sub class \lstinline{Constant}. It takes an argument \lstinline{factor} which gives the initial value of all weights.

A second choice is random initial weights, where the class \lstinline{Randomize} initializes the weights based on a uniform distribution. Also this class takes the \lstinline{factor} argument, which defines the interval. By default, the interval is [-1,1], which corresponds to \lstinline{factor=1}.

\subsubsection{The \lstinline{Metropolis} class}
This class is the true sampling class, where the magic sampling is done. Three sampling methods are implemented:
\begin{itemize}
	\item \lstinline{BruteForce} is the standard Metropolis sampling, where a particle is moved in a totally random direction and the move is accepted if the new probability is high enough.

	\item \lstinline{ImportanceSampling} is a more advanced version of the Metropolis algorithm, where the particle is moved in the same direction as the quantum force.
	
	\item \lstinline{GibbsSampling} is not directly related to the Metropolis algorithm, it is a simple method which is widely used in Boltzmann machines.
\end{itemize}
The sub classes need to have the function \lstinline{acceptMove()}, where the particle is moved and the the move is either accepted or rejected. To get the new positions, one need to call \lstinline{updatePositions()}. which is member of the super class. 

\subsubsection{The \lstinline{Optimization} class}
The next class is the \lstinline{Optimization} class, where the weight update is performed in the function \lstinline{updateWeights()}. Also the instant gradients (the gradient for each step) is calculated here, in the function \lstinline{getAllInstantGradients()}.

Two gradient based stochastic methods are implemented: \lstinline{StochasticGradientDescent} and \lstinline{ADAM}, with descriptive names. They both takes an argument \lstinline{gamma} which is the prefactor in front of the momentum. The reader can consult chapter \eqref{chp:optimization} for details on how the optimization methods work. 

\subsubsection{The \lstinline{Plotter} class}
Not sure if I will keep this as a class

\subsubsection{The \lstinline{RNG} class}
The random number generator (RNG) was implemented as a class to ease the switch between different RNGs. Each subclass need to contain the following functions:
\begin{itemize}
	\item \lstinline{nextInt(int upperLimit)} returns the next number in the RNG sequence as an integer between 0 and \lstinline{upperLimit}.
	
	\item \lstinline{nextDouble()} returns the next number in the RNG sequence as a double between 0 and 1.
	
	\item \lstinline{nextGaussian(double mean, double standardDeviation)} returns the next number in the RNG sequence, regenerated by a normal distribution with mean value \lstinline{mean} and standard deviation \lstinline{standardDeviation}.
\end{itemize}
The two available RNGs are the Mersenne Twister number generator, \lstinline{MersenneTwister} and... . For the theory behind thoe methods, see section \eqref{sec:RNG}. 

\subsubsection{The \lstinline{WaveFunctions} class}
Last, but not least, the \lstinline{WaveFunctions} class contains all the wave function related computations. We have already mentioned it, but all the details are still to be stressed. 

The required functions in the wave function elements are
\begin{itemize}
	\item \lstinline{updateArrays(Eigen::VectorXd positions, int pRand)} which update position dependent arrays recursively with respect to the new positions, \lstinline{positions} and the changed position index \lstinline{pRand}. 
	
	\item \lstinline{resetArrays()} set the arrays back to the old values when a move is rejected.
	
	\item \lstinline{initializeArrays(Eigen::VectorXd positions)} initialize all arrays at the beginning. This is the only moment when the arrays cannot be updated recursively. 
	
	\item \lstinline{updateParameters(Eigen::MatrixXd parameters, int elementNumber)} updates the weights. All weights of the system are stored in the parent matrix \lstinline{parameters}, while each wave function element has child weight matrices and arrays which are mapped from the parent. They are all updated in this function. \lstinline{elementNumber} is the number of the element, and is unique for all the wave function elements.
	
	\item \lstinline{evaluateRatio()} returns the ratio between the new and the old probability, \\ $|\Psi_T(\bs{r}_{\text{new}})|^2/|\Psi_T(\bs{r}_{\text{old}})|^2$
	
	\item \lstinline{computeFirstDerivative(int k)} returns the first derivative of the wave function element with respect to the position index \lstinline{k}.
	
	\item \lstinline{computeSecondDerivative()} returns the second derivative of the wave function element with respect to all position indices. 
	
	\item \lstinline{computeFirstEnergyDerivative(int k)} returns the derivative of the position \lstinline{k} first derivative of the wave function element with respect to all the weights, $\partial/\partial \alpha_i \nabla_k ln(\psi)$. The outcome is an array.
	
	\item \lstinline{computeSecondEnergyDerivative()} returns the derivative of the position second derivative of the wave function element with respect to all the weights, $\sum_k\partial/\partial \alpha_i \nabla_k^2 ln(\psi)$. The outcome is an array.
\end{itemize}
The wave function elements implemented are 
\begin{itemize}
	\item \lstinline{Gaussian} is the simple Gaussian function.
	\item \lstinline{PadeJastrow} is the Padé-Jastrow factor.
	\item \lstinline{SlaterDeterminant} is the Slater determinant.
	\item \lstinline{MLGaussian} is the Gaussian part derived from the Boltzmann machines.
	\item \lstinline{NQSJastrow} is the product part derived from the Boltzmann machines. 
\end{itemize}

New wave function elements can easily be implemented, all one needs to do is to calculate all the derivatives and specify how to update the position dependent arrays recursively. 

\subsection{How to set sub classes?}
We have now described all the available super classes and sub classes, but how do we set them? As hinted in the beginning of the chapter, the entire system should be specified in \lstinline{main.cpp}. For example, a harmonic oscillator Hamiltonian can be set by
\begin{lstlisting}[language=c++]
system->setHamiltonian(new HarmonicOscillator(system));
\end{lstlisting}
which is calling the function \lstinline{setHamiltonian} in the class \lstinline{System}. This function sets the official Hamiltonian object to \lstinline{HarmonicOscillator}, such that every time we call the super class \lstinline{Hamiltonian}, we are forwarded to \lstinline{HarmonicOscillator}. The \lstinline{System} class is basically filled with functions that set objects and scalars. To make those objects and scalars available in other classes, the \lstinline{System} header is equipped with get-functions. For instance, there exist a function 
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}
class Hamiltonian* getHamiltonian() { return m_hamiltonian; }
\end{lstlisting}
which returns the correct Hamiltonian sub class. In the other classes where the \lstinline{System} objects appears as \lstinline{m\_system}, the local energy can be found by
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}
double localEnergy = m_system->getHamiltonian->computeLocalEnergy();
\end{lstlisting}
Similar functions exist for other essential objects, arrays and scalar. 
\fi

\section{Running the code}
The software is freely available on \url{github.com/evenmn/VMC} under MIT license, summarized with "do whatever you want". Officially, the MIT license says \cite{noauthor_mit_nodate}\bigskip

\textit{"Permission is hereby granted, free of charge, to any person obtaining a copy
	of this software and associated documentation files (the "Software"), to deal
	in the Software without restriction, including without limitation the rights
	to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
	copies of the Software"}

We encourage reuse of the code.

\subsection{Download}
The code can be downloaded from github by cloning the repository \url{github.com/evenmn/VMC}. Prerequisites are MPI, Eigen and the automatized blocking code developed by Marius Jonsson. 
\begin{itemize}
	%\itemsep-0.6em
	\item In Linux, MPI can be installed by\\
	\lstinline{sudo apt-get install libopenmpi-dev}\\
	\lstinline{sudo apt-get install openmpi-bin}
	\item To install Eigen, see \url{http://eigen.tuxfamily.org/}.
	\item The automatized blocking code can be cloned from \url{https://github.com/computative/block}.
\end{itemize}

\subsection{Build}
The code can either be built using CMake or QMake in QT-creator. 

\subsubsection{CMake}
Go to the VMC prefix, and run the four commands
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}
mkdir build
cd build
cmake ../
make -j4
\end{lstlisting}
or one can simply run \lstinline{./CompileVMC}. The executable is then found in the \lstinline{build} folder.

\subsubsection{QMake (QT-Creator)}
\begin{itemize}
	%\itemsep-0.6em
	\item Download QT-Creator from \url{https://www.qt.io/download}.
	\item Configure \lstinline{QMC.pro}.
\end{itemize}
After the configuration, the executable can be found in the building folder, by default named \lstinline{build-VMC-...}.

\subsection{Run}
Before the code is run, the system of interest should be specified. There are multiple ways of doing this: one can either use the provided \lstinline{main.cpp} with all possible settings, create a new more minimalistic \lstinline{main.cpp} or use a configuration to specify the system. 

\subsubsection{Create \lstinline{main.cpp}}
The simplest possible main file one can write, is probably
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language={C++}]
int numberOfDimensions =  2;
int numberOfParticles = 6;
int numberOfSteps = int(pow(2, 20));
int maxNumberOfIterations = 1000;
double learningrate = 0.1;
double omega = 1.0;

System *QD = new System();

QD->setNumberOfParticles(numberOfParticles);
QD->setNumberOfDimensions(numberOfDimensions);
QD->setNumberOfMetropolisSteps(numberOfSteps);
QD->setFrequency(omega);
QD->setLearningRate(learningRate);

QD->setBasis(new Hermite(QD));

std::vector<class WaveFunction *> waveFunctionElements;
waveFunctionElements.push_back(new Gaussian(QD));
waveFunctionElements.push_back(new SlaterDeterminant(QD));
waveFunctionElements.push_back(new PadeJastrow(QD));

QD->setWaveFunctionElements(waveFunctionElements);
QD->setHamiltonian(new HarmonicOscillator(QD));
QD->runIterations(maxNumberOfIterations);
\end{lstlisting}
where we look at a two-dimensional circular quantum dot containing 6 electrons using a standard variational Monte-Carlo calculation. For more inspiration, see the provided \lstinline{main.cpp}. When the main file is implemented, the code can be run using
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language={bash}]
mpirun -n 4 build/dotnet
\end{lstlisting}
where \lstinline{dotnet} is the executable and we run 4 parallel processes. 

\subsubsection{Write configuration file}
Second, one can specify the system partly or entirely by a configuration file. The config file overwrites the settings in main. We have provided two config files, \lstinline{config} and \lstinline{config\_extended}, where the first one is limited and is dependent on settings in main, while the second contains all possible settings. We can specify a corresponding system to the one above, using the configuration file
\lstset{basicstyle=\scriptsize}
\begin{lstlisting}[language={bash}]
numDimensions: 2
numParticles: 6
numSteps: 1048576
numIterations: 1000
learningRate: 1.0
omega: 1.0
basis: hermite
waveFunction: VMC
hamiltonian: harmonicOscillator
\end{lstlisting}
and run the code using
\begin{lstlisting}[language={bash}]
mpirun -n 4 build/dotnet config
\end{lstlisting}
where we run 4 parallel processes, \lstinline{dotnet} is the executable and \lstinline{config} is the configuration file. 
