\chapter{Quantum Monte-Carlo Methods} \label{chp:methods}
\epigraph{Great quote.}{Author}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{Images/example.png}
	\caption{Caption}
\end{figure}

Some great methods for solving many-body quantum mechanical problems have been developed over the past decade. 

Configuration interaction, Hartree-Fock, Coupled-Cluster, quantum Monte-Carlo methods. In this chapter we will discuss variational Monte-Carlo with and without a machine learning trial wave function.

For our work, we will focus on variational Monte-Carlo 
We will focus on the Hartree-Fock and variational Monte Carlo methods and give a detailed explanation of those methods. Additionally, the well-known methods configuration interaction and coupled cluster will be described briefly for some kind of completeness. 

Monte Carlo methods in quantum mechanics are a bunch of methods that are built on diffusion processes, and includes Variational Monte Carlo (VMC), Diffusion Monte Carlo (DMC) and others. The common denominator is that we move particles in order to find the optimal configuration, usually where the energy is minimized. The particles can be moved isotropic, i.e., uniformly in all directions, or they can be affected by a drift force which makes the process anisotropic. 

\section{Isotropic processes}
In isotropic processes, we have random walks where the particles move randomly in space which falls under the category Markov chains. If we assume constant timestep, the step index can be considered the time, thus we have a time-dependent probability density $P(x,t)$. This probability density needs to satisfy the isotropic diffusion equation,
\begin{equation}
\frac{\partial P(\bs{x},t)}{\partial t}=D\frac{\partial^2}{\partial \bs{x}^2}P(\bs{x},t).
\end{equation}

\section{Anisotropic processes}
For anisotropic processes, we have a drift and the moves are no longer considered random but falls still under the category Markov chains. Because of the drift, we need to rewrite the diffusion equation and we end up with the Fokker-Planck equation,
\begin{equation}
\frac{\partial P(\bs{x},t)}{\partial t}=D\frac{\partial}{\partial \bs{x}}\left(\frac{\partial}{\partial \bs{x}}-F\right)P(\bs{x},t)
\end{equation}
which needs to be satisfied. The new positions in coordinate space are given as solution of the Langevin equation 
\begin{equation}
\frac{\partial \bs{x}(t)}{\partial t}=D\bs{F}(\bs{x}(t))+\eta
\end{equation}

\section{Variational Monte-Carlo} \label{subsec:vmc}
The variational Monte-Carlo (hereafter, VMC) method is today widely used when it comes to the study of ground state properties of quantum mechanical systems. It is a Markov chain Monte-Carlo method which makes use of Metropolis sampling, and has been used in studies of fermionic systems since the 1970's. \cite{deb_variational_2014} If we go back to the variational principle in equation \eqref{eq:variationalprinciple}, we see that by choosing a wave function which satisfies the criteria, we will get an energy larger or equal to the ground state energy. \bigskip

There are two main problems we need to solve
\begin{enumerate}
	\item We seldomly know the correct wave function
	\item The integral we need to find the energy is hard or impossible to solve
\end{enumerate}
Let us first determine the last problem, which often is considered as the root of all evil. Solving this integral analytically is impossible, but we can approximate it with a sum,
\begin{align}
E &\leq \frac{\int\Psi_T(\bs{r})^*\hat{\mathcal{H}}\Psi_T(\bs{r}) d\bs{r}}{\int\Psi_T(\bs{r})^*\Psi_T(\bs{r}) d\bs{r}} \notag\\
& = \int \mathcal{P}(\bs{r}) E_L(\bs{r}) d\bs{r} \notag\\
& \approx \frac{1}{M}\sum_{i=1}^ME_L(\bs{r}_i) \label{eq:energysum}
\end{align}
which is a common trick in statistical physics. The local energy is defined as
\begin{equation}
E_L(\bs{r})\equiv\frac{1}{\Psi_T(\bs{r})}\hat{\mathcal{H}}\Psi_T(\bs{r})
\label{eq:local energy}
\end{equation}
and the $\bs{r}_i$ is withdrawn from the probability distribution $P(\bs{r})$, which is given by
\begin{equation}
\mathcal{P}(\bs{r})=\frac{|\Psi_T(\bs{r})|^2}{\int|\Psi_T(\bs{r})|^2d\bs{r}}.
\end{equation}
When increasing the number of energies drawn from the distribution, $M$, henceforth denoted as Monte-Carlo cycles, the standard error decreases and we get a more accurate energy. The error goes as $\mathcal{O}(1/\sqrt{M})$, and in the limit when $M$ goes to infinity, the error goes to zero,
\begin{equation}
\langle E\rangle=\lim_{M\to\infty} \frac{1}{M}\sum_{i=1}^ME_L(\bs{r}_i).
\end{equation}
For more statistical details, see \cite{deb_variational_2014}. 

So far, so good, but how about the first problem stated above? How do we find the correct wave function? In VMC, we define a wave function with variational parameters, which are adjusted in order to minimize the energy for every iteration. Of course, we need a decent initial guess, which is usually based on our physical intuition. We will later examine how much physical intuition we need to get an acceptable result. 

For every iteration, we run $M$ Monte-Carlo cycles where we withdraw a new position $\bs{r}_i$. Whether or not the proposed move should be accepted is determined by the Metropolis algorithm.

\section{Sampling algorithms}
\subsection{The Metropolis Algorithm}
Metropolis sampling is a method of accepting or rejecting moves in Markov chain, are is today widely used. The genius of the metropolis algorithm, is that the acceptance of a move is not based on the probabilities themselves, but the ratio between the new and the old probability. In that way, we avoid calculating the sum over all probabilities, which often is expensive or even impossible to calculate. 

If we denote $\bs{r}$ as the current state, and $\bs{r}'$ as the proposed state, we have a transition rule $P(\bs{r}\rightarrow\bs{r}')$ for going from $\bs{r}$ to $\bs{r}'$ and a transition rule $P(\bs{r}'\rightarrow\bs{r})$ for going the other way around. If we then assume that the rules satisfy \textit{ergodicity} and \textit{detailed balance}, we have the following relationship:
\begin{equation}
P(\bs{r}\rightarrow\bs{r}')\mathcal{P}(\bs{r})=P(\bs{r}'\rightarrow\bs{r})\mathcal{P}(\bs{r}').
\end{equation}

The next step is to rewrite the transition rules in terms of a sampling distribution $T(\bs{r}\rightarrow\bs{r}')$ and an acceptance probability $A(\bs{r}\rightarrow\bs{r}')$,
\begin{equation}
P(\bs{r}\rightarrow\bs{r}')=T(\bs{r}\rightarrow\bs{r}')A(\bs{r}\rightarrow\bs{r}').
\end{equation}
In order to satisfy the detailed balance, we need to choose $A(\bs{r}\rightarrow\bs{r}')$ such that
\begin{equation}
A(\bs{r}\rightarrow\bs{r}')=\text{min }\left[1,\frac{T(\bs{r}'\rightarrow\bs{r})\mathcal{P}(\bs{r}')}{T(\bs{r}\rightarrow\bs{r}')\mathcal{P}(\bs{r})}\right],
\label{eq:acceptance}
\end{equation}
since $A$ cannot be larger than 1. If the acceptance is higher than a random number between 0 and 1, the move is accepted.

\subsubsection{Brute-Force Sampling}
In its simplest form, \textbf{brute-force}, the move is proposed randomly both in magnitude and direction. Mathematically, we can write this as
\begin{equation}
\bs{r}'=\bs{r}+sd\bs{r}
\end{equation}
where $s$ is a random number which determines the distance to move and $d\bs{r}$ is a random direction that typically tells which particle to move. We obtain the naive acceptance probability when setting $T(\bs{r}\rightarrow\bs{r}')=T(\bs{r}'\rightarrow\bs{r})$, such that the it simplifies to
\begin{equation}
A(\bs{r}\rightarrow\bs{r}')=\text{min }\left[1,\frac{\mathcal{P}(\bs{r}')}{\mathcal{P}(\bs{r})}\right].
\end{equation}

However, with this approach a lot of moves will be rejected, which results in a significant waste of computing power. A better method is \textbf{importance sampling}.

\subsubsection{Importance Sampling}
Importance sampling is a more intelligent sampling method than the brute-force sampling, since the new position is based on an educated guess. To understand how it works, we need to take a quick look at diffusion processes. We start from the Fokker-Planck equation,
\begin{equation}
\frac{\partial P(\bs{r},t)}{\partial t}=D\nabla\left(\nabla-\bs{F}\right)P(\bs{r},t)
\end{equation}
which describes how a probability distribution $P(\bs{r},t)$ evolves in appearance of a drift force $\bs{F}$. In the case $\bs{F}=0$, the equation reduces to the diffusion equation with $D$ as the diffusion constant. This constant can be found from the so-called Einstein relation, which simplifies to $D=1/2$ in atomic units. 

The Langevin equation states that a diffusion particle tends to move parallel to the drift force in the coordinate space, but because of a random variable $\bs{\eta}$ this is not always true. The equation reads
\begin{equation}
\frac{\partial \bs{r}(t)}{\partial t}=D\bs{F}(\bs{r}(t))+\bs{\eta}.
\label{eq:langevin}
\end{equation}
Given a position $\bs{r}$, the new position $\bs{r}'$ can be be found by applying forward-Euler on equation \eqref{eq:langevin},
\begin{equation}
\bs{r}'=\bs{r}+D\bs{F}(\bs{r})\Delta t + \bs{\xi}\sqrt{\Delta t}
\end{equation}
where $\Delta t$ is a fictive time step and $\bs{\xi}$ is a Gaussian random variable. The next thing we want to find, is an expression for the drift force $\bs{F}$ which makes the system converge to a stationary state. 

A stationary state is found when the probability density $P(\bs{r})$ is constant in time, i.e, when the left-hand-side of Fokker-Planck is zero. In that case, we can write the equation as
\begin{equation}
\nabla^2P(\bs{r})=P(\bs{r})\nabla\bs{F(\bs{r})}+\bs{F(\bs{r})}\nabla P(\bs{r}).
\end{equation}
In the next, we assume that the drift force has the form $\bs{F(\bs{r})}=g(\bs{r})\nabla P(\bs{r})$, since the force should point to a higher probability. We can then go further and write
\begin{equation}
\nabla^2 P(\bs{r})\big(1-P(\bs{r})g(\bs{r})\big)=\nabla\big(g(\bs{r})P(\bs{r})\big)\nabla P(\bs{r})
\end{equation}
which is satisfied when $g(\bs{r})=1/P(\bs{r})$. We then get the drift force 
\begin{equation}
\bs{F}(\bs{r})=2\frac{\nabla\Psi_T(\bs{r})}{\Psi_T(\bs{r})}.
\end{equation}
which is also known as the \textit{quantum force}.

The remaining part is how to decide if a proposed move should be accepted or not. For this, we need to find the sampling distributions $T(\bs{r}\rightarrow\bs{r}')$ from equation \eqref{eq:acceptance}, which are just the solutions of the Fokker-Planck equation. The solutions read
\begin{equation}
G...
\end{equation}
which is called Green's function. The acceptance probability for importance sampling can finally be written as
\begin{equation}
A(\bs{r}\rightarrow\bs{r}')=\text{min }\left[1,\frac{G(\bs{r},\bs{r}')\mathcal{P}(\bs{r}')}{G(\bs{r}',\bs{r})\mathcal{P}(\bs{r})}\right].
\end{equation}

\subsection{Gibbs' sampling}
Gibbs' sampling is a popular algorithm when it comes to 