\chapter{Introduction}
The properties and behavior of quantum many-body systems are determined by the laws of quantum physics which have been known since the 1930s. The time-dependent Schrödinger equation describes the binding energy of atoms and molecules, as well as the interaction between particles in a gas. Besides, it has been used to determine the energy of artificial structures like quantum dots, nanowires and ultracold condensates. As the quantum theory is the most precisely tested in the history of science, computer experiments are in principle capable of obtaining the energy as precise as laboratory experiments, and can in that sense replace laboratory experiments \cite{odom_new_2006}.

Although we know the laws of quantum mechanics, many challenges are encountered when calculating real-world problems. First, interesting systems often involve a large number of particles, which causes expensive calculations. Second, the correct wave functions are seldom known for complex systems, which is vital for measuring the observable accurately. Together, they are known as the many-body problem, which we in this thesis will attempt to solve using machine learning.

\section{The many-body problem}
In quantum mechanics, a many-body system contains three or more interacting particles. These interactions create so-called quantum correlations, which makes the wave function of the system a complicated object holding a large amount of information. As a consequence, exact or analytical calculations become impractical or even impossible, which is known as the many-body problem. Indeed, Paul Dirac recognized those problems already in 1929:

\begin{shadequote}{
		The general theory of quantum mechanics is now almost complete... ...The underlying physical laws necessary for the mathematical theory of a large part of physics and the whole of chemistry are thus completely known, and the difficulty is only that the exact application of these laws leads to equations much too complicated to be soluble. \par Paul M. Dirac, \emph{Quantum Mechanics of Many-electron Systems}, \cite{dirac_paul_adrien_maurice_quantum_1929}.}
\end{shadequote}

There are numerous approaches to solve this problem where approximative methods often are used to reduce the sometimes extreme computational cost. Popular methods include the Hartree-Fock method, which replaces the interaction by a mean-field, and methods like Full Configuration Interaction (FCI) and Coupled Cluster which seek to solve the problem by approximating the wave function with expansions. Lastly, quantum Monte Carlo (QMC) methods are different approaches attempting to solve the problem directly using a stochastic evaluation of the integrals occurring from the Schrödinger equation. 

What all these methods have in common, is that they require significant amounts of physical intuition to work. In general, prior knowledge of the wave function, covering all the interactions and the cusps, is required. This knowledge is often unavailable, especially for complex systems, which also make accurate estimates of the observable unavailable. In this thesis, we will try to bypass this problem by inventing more flexible and robust methods that allow a relatively bad wave function guess. A natural base for this is the machine learning algorithms, as they can "learn" themselves and thus hopefully find reasonable estimates through a training process. The apparent link between machine learning and quantum mechanics are the QMC methods, since they both are based on minimizing a \textit{cost function} in order to obtain optimal configurations. The connection between machine learning and QMC methods, in particular, variational Monte Carlo (VMC), will be discussed thoroughly throughout this thesis

\section{Machine learning} \label{sec:machinelearning}
Machine learning has recently achieved immense popularity in fields such as computer vision, economics, autonomy - and science, due to its ability to learn without being explicitly programmed. As a branch of artificial intelligence, machine learning is based on studies of the human brain and attempts to recreate the way neurons in the brain process information. 

Especially the artificial neural networks have experienced significant progress over the past decade, which can be attributed to an array of innovations. Most notably, the convolutional neural network (CNN) AlexNet \cite{krizhevsky_imagenet_2012} managed to increase the top-5 test error rate of image recognition with a remarkable 11.1\% compared to the second-best back in 2012! Today, the CNNs have been further improved, and they are even able to beat humans in recognizing images \cite{alom_history_2018}. Also, speech recognition algorithms have lately been revolutionized, thanks to recurrent neural networks (RNNs), and exceptionally long short-term memory (LSTM) networks. Their ability to recognize sequential (time-dependent) data made the technology good enough for entry to millions of people's everyday-life through services such as Google Translate \cite{wu_googles_2016}, Apple's Siri \cite{smith_ios_2016} and Amazon Alexa \cite{noauthor_bringing_nodate}. It is also interesting to see how machine learning has made computers eminent tacticians using reinforcement learning. The Google-developed program AlphaGo demonstrated this by beating the 9-dan professional Sedol in the board game Go \cite{noauthor_alphago_nodate}, before an improved version, AlphaZero, beat the at that time highest-rated chess computer, Stockfish, in chess \cite{klein_mikeklein_googles_nodate}. Both these scenarios were unbelievable just a couple of decades ago.

Even though all these branches are both exciting and promising, they will not be discussed further in this work, since they will not work for our purposes. The reason is that they initially require a data set with known outputs in order to be trained; they obey so-called \textit{supervised} learning. For our quantum mechanical systems, we do not have those targets and need to rely on \textit{unsupervised} learning with the focus on restricted Boltzmann machines (RBMs). Lately, some effort has been put into this field, known as quantum machine learning. \citet{carleo_solving_2017} demonstrated the link between RBMs and QMC and named the states \textit{neural-network quantum states} (NQS). They used the technique to study the Ising model and the Heisenberg model. \citet{pfau2019abinitio} went further and predicted the dissociation curves of the nitrogen molecule using a so-called fermionic neural network, and \citet{flugsrud_vilde_moe_solving_nodate} investigated ground-state properties of circular quantum dots, also using RBMs. We will extend the work she did to larger quantum dots.

\section{Quantum dots}
Quantum dots are often called artificial atoms because of their common features to real atoms, and their popularity is increasing due to their applications in semiconductor technology. For instance, quantum dots are expected to be the next big thing in display technology due to their ability to emit photons of a specific wavelength in addition to being 30\% more energy efficient than today's LED displays \cite{manders_8.3:_2015}. Samsung already claim that they use this technology in their displays \cite{noauthor_2019_nodate}.

Another reason why we are interested in simulating quantum dots is the fact that there exist experiments that can be used as benchmarks. Due to very strong confinement in the $z$-direction, the experimental dots, made by patterning GaAs/AlGaAs heterostructures, become essentially two-dimensional \cite{marzin_photoluminescence_1994,brunner_sharp-line_1994}. For that reason, our main focus in this work is on two-dimensional dots, but also dots of three dimensions will be investigated. Quantum dots also allow the study of Wigner crystals, as their strength can be decreased such that the interaction energy dominates the kinetic energy. 

\section{Computer experiments}
The advent of computer technology has offered us a new window of opportunity for studies of quantum (and many other) problems. It serves as a third way of doing science which is based on simulations, in contrast to laboratory experiments and analytical approaches. In a broad sense, by simulations, we mean computational models of reality based on physical laws, such as the fundamental Schrödinger equation. Such models have value when they enable them to make predictions or to provide new information which is otherwise impossible or too costly to obtain. In this respect, QMC methods represent an illustration and an example of what is the potential of such methodologies.

The use and popularity of QMC methods have increased as personal computers and computer clusters have been more powerful. With today's reliable computers, we see those methods as a natural choice when ground state properties of quantum mechanical systems are investigated. Even the most straightforward method, VMC, does typically yield excellent results, and the more complicated diffusion Monte Carlo (DMC) is in principle capable of employing exact results. They both appear to have among the highest performance-to-cost ratios out of all the quantum many-body methods. 

Albeit the fact that the QMC methods relatively recently have been applied to large-scale calculations, some of the ideas go back to the time before the invention of the electronic computer. Already in the 1940's, Enrico Fermi revealed the similarities between the imaginary time Schrödinger equation and stochastic processes in statistical mechanics. The first attempt to use this link on actual calculations was performed by a group of scientists at Los Alamos National Laboratory in the early 1950's when they tried to compute the ground state energy of the hydrogen molecule using a simple version of VMC \cite{bajdich_electronic_2010}. Around the same time, \citet{metropolis_monte_1949} introduced the original Metropolis algorithm, which estimates the integrals by moving particles randomly in an ergodic scheme and rejecting inappropriate moves. This method was further improved in the late 1950s when \citet{KALOS1979153} laid down the statistical and mathematical framework for the Green's function in QMC methods, and \citet{hastings_monte_1970} developed an efficient algorithm based on the theory, where the particles are moved after an educated guess. The use of the QMC methods on many-fermion systems was first done by \citet{ceperley_quantum_1986} in the 1980's and started a new era of stochastic methods applied to electronic structure problems. 

\section{Ethics in science}
In science as an entirety, there are some general guidelines that we all should follow in order to maintain ethical behavior. Firstly, one should always have respect for other's work, and the authors should be credited whenever one uses other's work, no matter the scope. With work, we mean illustrations, text, code, methods, algorithms et cetera, which are covered by the Copyright Act (in Norway, åndsverkloven). Secondly, all the research that one does should always be detailed in a such way that others can reproduce the experiments and results. This means that all the factors which possibly have a significant impact on the experiments should be described, and computer experiments are no exception. Lastly, there are unfortunately many examples of misuse of knowledge throughout history, which obviously has to be avoided.

In our specific work, most of the ethical aspects related to the use of machine learning, which can cause fatal consequences if it is not used correctly and carefully. The fact that machine learning allows the computers to learn things themselves have made profiled people like Stephen Hawking \cite{cellan-jones_hawking:_2014} and Elon Musk \cite{vance_elon_2015} warn us that they can be greatly misused if they are set on learning the wrong things. Every person who develops machine learning algorithms should take this warning seriously, remember that in the end, there is one of us who end up creating the multi-headed monster \textit{Hydra}.

\section{Our goals and contributions} \label{sec:goals}
The goals of this thesis are mainly related to the development and investigation of a quantum many-body method that requires less physical intuition. In order to do this, the software implementation is essential, which obviously is a significant part of the work and thereby the goals. This also includes a VMC code for benchmark purposes, in addition to the RBM code. Further, the next goal is naturally to obtain some results, which will mostly come from the quantum dots. In the end, we will provide a thorough comparison of the VMC and RBM results, inclusive wave function studies. We can summarize the goals in a list
\begin{itemize}
	\item Develop a VMC code for the study of large fermionic systems.
	\item Implementing RBMs as flexible trial wave function guesses.
	\item Study ground state properties of quantum dots and atoms, including energy, variance and electron densities.
	\item Make a critical evaluation of the RBMs compared with VMC studies.
\end{itemize}

We believe that machine learning-based methods are the next big thing in many-body quantum mechanics, and our contribution to the field is therefore to investigate one of the many such approaches. There are also some fascinating similarities between the typical sampling process behind Boltzmann machines and the QMC methods, and by revealing the actual mechanisms, we might be able to develop more robust methods. 

\section{Our developed code}
There exist plenty of commercial software programs for solving the quantum many-body problem, and they are often efficiency optimized. In general, it is wise to use already existing code and not try to reinvent the wheel, but in our case, we will investigate a new approach, which forces us to write the code from scratch. 

Our VMC solver is written in object-orientated C++ inspired by the example implementation of \citet{ledum_simple_2016}, and our basis set is assumed to be given in Cartesian coordinates. The goal is not to compete with the performance of commercial software, but we will still make significant efforts to develop an efficient code. As far it is possible, all operations are vectorized using the open-source template library Eigen, which again is based on the tremendously fast packages BLAS and LAPACK. We used the profiling tool Valgrind to analyze which functions that require most computer power and thus which parts of the code that should be made more efficient. Additionally, the message passing interface (MPI) lets us parallelize the code and thereby run on computer clusters. For implementation details, see chapter \ref{chp:WFE} and \ref{chp:rbmimplementation}. The VMC code can in its entirety be found on \url{https://github.com/evenmn} under the MIT license. 

\section{Structure of the thesis}
Fundamental theory, including many-body quantum physics and basic machine learning, is given in chapter \ref{chp:quantum}-\ref{chp:systems}. The theory behind the RBMs and VMC is given in chapter \ref{chp:restricted}-\ref{chp:methods} as our advanced theory, and their optimization schemes and implementation is presented in chapter \ref{chp:WFE}-\ref{chp:rbmimplementation}. The remaining chapters include presentation and discussion of the results and a brief conclusion.
