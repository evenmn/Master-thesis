\chapter{Derivation of Wave Function Elements} \label{chp:WFE}
In chapter \eqref{chp:quantum} we presented the basic principles behind a many-body trial wave function, including the Slater determinant and the well-known Padé-Jastrow factor. Further in chapter \eqref{chp:systems}, the common basis functions of the quantum dot and atomic systems were given, and in the previous chapter, \eqref{chp:machinelearning}, we explained how to create wave functions using Boltzmann machines. This means that all wave function elements used in this thesis already are presented, and in this chapter they are all collected, together with their derivatives and various optimizations. The calculations below are based on two main assumptions:
\begin{enumerate}
	\item For each time step, we change one position coordinate only, i.e, move a particle along one of the principal axis.
	\item A variational parameter $\alpha_i$ appears in only one of the wave function elements.
\end{enumerate}
The first assumption is useful when updating position dependent arrays. Typically, we only need to update a coordinate of an array or a row of a matrix when this assumption is raised, which is hugely beneficial with respect to the computational time. The last assumption is makes all wave function elements independent, which obviously makes life easier. We will now show how the local energy can be split up and calculated independently for the different elements, and then we will take a look at how the parameters are updated.

\section{Kinetic Energy Calculations}
The local energy, defined in equation \eqref{eq:local energy}, is
\begin{align}
E_L &=\frac{1}{\Psi_T(\bs{r})}\hat{\mathcal{H}}\Psi_T(\bs{r})\\
&=\sum_{k=1}^M\Big[-\frac{1}{2}\Big(\frac{1}{\Psi_T(\bs{r})}\nabla_k^2\Psi_T(\bs{r})\Big) + \mathcal{V}\Big].
\end{align}
The first term, which is the kinetic energy term, is the only wave function-dependent one. It will in this chapter be evaluated for various wave function elements. From the definition of differentiation of a logarithm, we have that
\begin{equation}
\frac{1}{\Psi_T(\bs{r})}\nabla_k\Psi_T(\bs{r})=\nabla_k\ln\Psi_T(\bs{r}),
\end{equation}
which provides the following useful relation 
\begin{equation}
\frac{1}{\Psi_T(\bs{r})}\nabla_k^2\Psi_T(\bs{r})=\nabla_k^2\ln\Psi_T(\bs{r}) + (\nabla_k\ln\Psi_T(\bs{r}))^2.
\end{equation}
Consider a trial wave function, $\Psi_T$, consisting of a product of $p$ wave function elements, $\{\phi_1, \phi_2\hdots\phi_p\}$,
\begin{equation}
\Psi_T(\bs{r}) = \prod_{i=1}^p\phi_i(\bs{r}).
\end{equation}
The kinetic energy related to this trial wave function is then computed by
\begin{equation}
\frac{1}{\Psi_T(\bs{r})}\nabla_k^2\Psi_T(\bs{r})=\sum_{i=1}^p\nabla_k^2\ln\phi_i(\bs{r}) + \Big(\sum_{i=1}^p\nabla_k\ln\phi_i(\bs{r})\Big)^2,
\end{equation}
which can be found when all local derivatives $\nabla_k^2\ln\phi_i(\bs{r})$ and $\nabla_k\ln\phi_i(\bs{r})$ are given. For each wave function element given below, those local derivatives will be evaluated. In addition, we need to know the derivative of local energy with respect to the variational parameters in order to update the parameters correctly. 

\section{Parameter Update}
In gradient based optimization methods, as we use, one needs to know the gradient of the expectation value of local energy with respect to all variational parameters $\alpha_i$, 
\begin{equation}
\partial_{\alpha_i} \langle E_L\rangle\equiv\frac{\partial \langle E_L(\alpha_i)\rangle}{\partial \alpha_i}.
\end{equation}
Since we are dealing with an expectation value, this gradient can be found from
\begin{equation}
\partial_{\alpha_i} \langle E_L\rangle=2\Big(\langle E_L\partial_{\alpha_i}\ln\Psi_T\rangle - \langle E_L\rangle\langle\partial_{\alpha_i}\ln\Psi_T\rangle\Big)
\end{equation}
which means that we need to calculate the expectation values $\langle E_L\partial_{\alpha_i}\ln\Psi_T\rangle$ and $\langle\partial_{\alpha_i}\ln\Psi_T\rangle$ in addition to the local energy. Those expectation values are found from the integrals
\begin{equation}
\langle\partial_{\alpha_i}\ln\Psi_T\rangle = \int_{-\infty}^{\infty}d\bs{r}P(\bs{r})\partial_{\alpha_i}\ln\Psi_T(\bs{r})
\end{equation}
and
\begin{equation}
\langle E_L\partial_{\alpha_i}\ln\Psi_T\rangle = \int_{-\infty}^{\infty}d\bs{r}P(\bs{r})E_L(\bs{r})\partial_{\alpha_i}\ln\Psi_T(\bs{r}),
\end{equation}
which can also be found by Monte-Carlo integration.

\section{Optimizations}
How much a wave function element can be optimized heavily depends on the specific form of the element. For instance, sometimes the previous and present $\nabla_k\ln\phi_i$ are closely related, and only differ with a few calculations, while for some other elements they are not related at all. Those subjective optimizations will therefore be described when presenting each wave function element. 

However, there are still optimizations that apply to all elements and give great speed-up. An example is when calculating the ratio between the previous and present wave functions
for all wave function elements instead of the wave function itself. Firstly, this is usually cheaper to calculate than the wave function itself because we are working in the logarithm space. Secondly, the ratio is actually what we use in the sampling, so it is a natural thing to calculate. The total wave function ratio is just the product of all the wave function element ratios
\begin{equation*}
	\frac{\Psi_T^{\text{new}}}{\Psi_T^{\text{old}}}=\prod_{i=1}^p\frac{\phi_i^{\text{new}}}{\phi_i^{\text{old}}}
\end{equation*}

\section{Derivatives}
\subsection{Simple Gaussian}
A natural starting point is the Gaussian function, since it appears in standard variational Monte-Carlo computations of quantum dot systems. For $P$ number of particles and $F$ free dimensions, the function is given by
\begin{equation*}
\Psi( \bs{x}; \alpha)=\exp\Big(-\frac{1}{2}\omega\alpha\sum_{i=1}^Pr_i^2\Big)=\exp\Big(-\frac{1}{2}\omega\alpha\sum_{i=1}^Fx_i^2\Big)
\end{equation*}
similarly to the function presented in section \eqref{sec:quantumdot}. $\omega$ is the oscillator strength and $\alpha$ is a variational parameter, which for non-interacting atoms is 1. Due to the presence of $r_i^2$, the function can easily be treated both in Cartesian and spherical coordinates, but in this thesis we will focus on the former. 

The gradient with respect to coordinate $x_k$ is
\begin{equation*}
\nabla_k\ln\Psi(\alpha)=-\omega\alpha x_k
\end{equation*}
and the corresponding Laplacian is
\begin{equation*}
\nabla_k^2\ln\Psi(\alpha)=-\omega\alpha.
\end{equation*}
Finally, for the parameter update we have that
\begin{equation}
\partial_{\alpha}\ln\Psi = -\frac{1}{2}\omega\sum_{i=1}^Mx_i^2.
\end{equation}

Since this wave function element is quite simple, there is no special optimization available that will cause a noticeable performance improvement. One can calculate $\omega\alpha$ once to save a few floating point operations, and of course calculate the probability ratio. Collecting all expressions, we end up with
\begin{empheq}[box={\mybluebox[5pt]}]{align}
\frac{\Psi_{\text{new}}^2}{\Psi_{\text{old}}^2}&=\exp\Big(\omega\alpha(x_{i,\text{old}}^2-x_{i,\text{new}}^2)\Big)\notag\\
\nabla_k\ln\Psi&=-\omega\alpha x_k\notag\\
\nabla_k^2\ln\Psi&=-\omega\alpha\\
\partial_{\alpha}\ln\Psi &= -\frac{1}{2}\omega\sum_{i=1}^Mx_i^2,\notag
\end{empheq}
where $i$ is the changed coordinate. 

\subsection{Padé-Jastrow Factor}
The Padé-Jastrow factor is introduced in order to take care of the correlations. It is specified in equation \eqref{eq:PadeJastrow}, 
\begin{equation*}
J(\bs{r}; \beta) = \exp\bigg(\sum_{i=1}^P\sum_{j>i}^P\frac{a_{ij}r_{ij}}{1+\beta r_{ij}}\bigg),
\end{equation*}
where $P$ is the number of particles, $r_{ij}$ is the relative distance between particle $i$ and $j$ and $\beta$ is a variational parameter. One challenge is that we operate in Cartesian coordinates, while the expressed Jastrow factor obviously is easier to handle in spherical coordinates. Since we need to differentiate this with respect to all free dimensions, we need to be careful not confuse the particle indices and coordinate indices. Let us define $i$ as the coordinate index and $i'$ as the index on the corresponding particle. With that notation, the gradient and Laplacian read
\begin{equation*}
\nabla_k\ln J=\sum_{j'\neq k'=1}^P\frac{\beta_{k'j'}}{(1+\gamma r_{k'j'})^2}\frac{x_k-x_j}{r_{k'j'}}
\end{equation*}
and
\begin{equation*}
\nabla_k^2\ln J=\sum_{j'\neq k'=1}^P\frac{\beta_{k'j'}}{(1+\gamma r_{k'j'})^2}\bigg[1-\Big(1+2\frac{\gamma r_{k'j'}}{1+\gamma r_{k'j'}}\Big)\frac{(x_k-x_j)^2}{r_{k'j'}^2}\bigg]\frac{1}{r_{k'j'}}
\end{equation*}
respectively, where $j$ is a coordinate index for the same direction as $k$ ($k=ndi$ with $d$ as the number of dimensions and $n$ as an integer).

\iffalse
The derivative of those again with respect to $\gamma$ are
\begin{equation*}
\partial_{\gamma}\nabla_k\ln J = -2 \sum_{j'\neq k'=1}^P\frac{\beta_{k'j'}}{(1+\gamma r_{k'j'})^3}(x_k-x_j)
\end{equation*}
and
\begin{equation*}
\partial_{\gamma}\nabla_k^2\ln J = -2 \sum_{j'\neq k'=1}^P\frac{\beta_{k'j'}}{(1+\gamma r_{k'j'})^3}\bigg[1-4\frac{\gamma r_{k'j'}}{1+\gamma r_{k'j'}}\frac{(x_k-x_j)^2}{r_{k'j'}^2}\bigg]
\end{equation*}
\fi
By defining 
\begin{equation*}
f_{ij}=\frac{1}{1+\gamma r_{ij}}\quad g_{ij}=\frac{x_i-x_j}{r_{i'j'}}\quad h_{ij}=\frac{r_{ij}}{1+\gamma r_{ij}}
\end{equation*}
the equations can be written as
\begin{empheq}[box={\mybluebox[5pt]}]{align}
\frac{J_{\text{new}}^2}{J_{\text{old}}^2}&=\exp\Big(2\sum_{j'=1}^N\beta_{i'j'}(h_{i'j'}^{\text{new}}-h_{i'j'}^{\text{old}})\Big)\notag\\
\nabla_k\ln J &=\sum_{j'\neq k'=1}^N\beta_{k'j'}\cdot f_{k'j'}^2\cdot g_{kj}\notag\\
\nabla_k^2\ln J &= \sum_{j'\neq k'=1}^N\frac{\beta_{k'j'}}{r_{k'j'}}f_{k'j'}^2\Big[1-(1+2\gamma h_{k'j'})g_{kj}^2\Big]\\
\partial_{\gamma}\nabla_k\ln J &=\sum_{j'\neq k'=1}^N\beta_{k'j'}\cdot f_{k'j'}^3(x_k-x_j)\notag\\
\partial_{\gamma}\nabla_k^2\ln J &= \sum_{j'\neq k'=1}^N \beta_{k'j'}\cdot f_{k'j'}^3\Big[1=4\gamma h_{k'j'}\cdot g_{kj}^2\Big]\notag,
\end{empheq}
with marked indices ($i'$) as the particle related ones and the unmarked ($i$) as the coordinate related ones. $i'$ is the moved particle. 

\subsection{Slater Determinant}
The Slater determinant is added to introduce anti-symmetry into the wave function, and as discussed in section \eqref{subsec:slater}, it can be split up in a spin-up part and a spin-down part,
\begin{equation*}
\Psi(\bs{x})=
|\hat{D}_{\uparrow}(\bs{x}_{\uparrow})|\cdot |\hat{D}_{\downarrow}(\bs{x}_{\downarrow})|.
\end{equation*}
$x_{\uparrow}$ are the coordinates of particles with spin up (defined as the first half of the coordinates) and $x_{\downarrow}$ are the coordinates of particles with spin down (defined as the last half of the coordinates). 

We can now utilize the logarithmic scale, 
\begin{equation*}
\ln\Psi=\ln|\hat{D}_{\uparrow}(\bs{x}_{\uparrow})|+\ln|\hat{D}_{\downarrow}(\bs{x}_{\downarrow})|
\end{equation*}
such that we only need to care about one of the determinants when differentiating, dependent on whether the coordinate we differentiate with respect to is among the spin-up or the spin-down coordinates:
\begin{equation*}
\nabla_k\ln\Psi=
\begin{cases} 
\nabla_k\ln|\hat{D}_{\uparrow}(\bs{x}_{\uparrow})| & \text{if} \quad k<F/2\\
\nabla_k\ln|\hat{D}_{\downarrow}(\bs{x}_{\downarrow})| & \text{if} \quad k\geq F/2.
\end{cases}
\end{equation*}
Before we go further, we will introduce a more general notation which cover both cases:
\begin{equation*}
\hat{D}\equiv \hat{D}_{\sigma}(\bs{x}_{\sigma})
\end{equation*}
where $\sigma$ is the spin. When summing, the sum is always over all relevant coordinates. 

Furthermore, we have that
\begin{equation*}
\nabla_k\ln|\hat{D}|=\frac{\nabla_k\detD}{|\hat{D}|}
\end{equation*}
and
\begin{equation*}
\nabla_k^2\ln|\hat{D}|=\frac{\nabla_k^2\detD}{|\hat{D}|}-\bigg(\frac{\nabla_k\detD}{|\hat{D}|}\bigg)^2
\end{equation*}

The first derivative of a determinant is given by Jacobi's formula, which reads
\begin{equation}
\label{eq:jacobi}
\frac{\nabla_i|\hat{A}|}{|\hat{A}|}=\tr(\hat{A}^{-1}\nabla_i\hat{A}),
\end{equation}
and the second derivative is then 
\begin{equation*}
\frac{\nabla_i^2|\hat{A}|}{|\hat{A}|}=\Big(\tr\big(\hat{A}^{-1}\nabla_i\hat{A}\big)\Big)^2+\tr\big(\hat{A}^{-1}\nabla_i^2\hat{A}\big) - \tr\big(\hat{A}^{-1}\nabla_i\hat{A}\hat{A}^{-1}\nabla_i\hat{A}\big)
\end{equation*}
where $\tr\big(\hat{B}\big)$ is the trace of matrix $\hat{B}$, i.e, the sum of all diagonal elements. $\nabla_i\hat{A}$ means that we differentiate the matrix component-wise with respect to coordinate $i$. The traces can then be written as sums,
\begin{equation*}
\tr(\hat{A}^{-1}\nabla_i\hat{A})=\sum_{j}A_{ji}^{-1}\nabla_iA_{ij}.
\end{equation*}
and
\begin{equation*}
	\tr(\hat{A}^{-1}\nabla_i^2\hat{A})=\sum_{j}a_{ji}^{-1}\nabla_i^2a_{ij}.
\end{equation*}

Using all the general matrix operations presented above, we end up with
\begin{equation*}
\nabla_k\ln|\hat{D}|=\sum_{j}d_{jk}^{-1}\nabla_kd_{kj}
\end{equation*}
and
\begin{equation*}
\nabla_k^2\ln|\hat{D}|=\sum_jd_{jk}^{-1}\nabla_k^2d_{kj}-\Big(\sum_jd_{jk}^{-1}\nabla_kd_{kj}\Big)^2
\end{equation*}

\subsubsection{Efficient calculation of Slater determinants}
As you might already have noticed, we need to calculate the inverse of the matrices every time a particle is moved. This is a pretty heavy task for the computer, where the standard way, LU decomposition, requires $\sim$ N$^3$ floating point operations for an N$\times$N matrix. \cite{trahan_computational_2006}. 

The good thing is that, by exploiting that only one row in the Slater matrix is updated for each step, we can update the inverse iteratively. 

Before we start finding an algorithm for this, we will introduce the reader to some common linear algebra concepts. First of all, the inverse of a matrix is given by the \textit{comatrix} transposed over its determinant
\begin{equation}
\hat{A}^{-1}=\frac{\hat{C}^T}{|\hat{A}|}
\end{equation}
where the comatrix is defined by the inner determinants of the matrix. \cite{weisstein_matrix_nodate} As a consequence, the determinant can be written as 
\begin{equation}
|\hat{A}|=\sum_{i,j}a_{ij}c_{ij}.
\end{equation}
As always, we are interested in the ratio between the wave functions, and since only a row is updated every time we move a particle, the ratio between the determinants can be expressed as
\begin{equation}
R\equiv \frac{|\hat{D}^{\text{new}}|}{|\hat{D}^{\text{old}}|}=\frac{\sum_{j}d_{ij}^{\text{new}}c_{ij}^{\text{new}}}{\sum_{j}d_{ij}^{\text{old}}c_{ij}^{\text{old}}}
\end{equation}
where the particle associated with the $i$'th row is moved. The $i$'th row of the comatrix is independent of the $i$'th row of the matrix itself, such that $c_{ij}^{\text{new}}=c_{ij}^{\text{old}}$. 


---------

In the end, we will take advantage of the fact that we only move one particle at a time. This means that one of the two determinants cancel when calculating the probability ratio used in Metropolis sampling. Since we do not have any variational parameters in the Slater determinant, we end up with three expressions for each determinant:

\begin{empheq}[box={\mybluebox[5pt]}]{align}
&\quad\text{if}\quad k<F/2:\notag\\
\frac{|\Psi_{\text{new}}|^2}{|\Psi_{\text{old}}|^2}&=
|\hat{D}_{\uparrow}(\bs{x}_{\uparrow}^{\text{new}})|^2/|\hat{D}_{\uparrow}(\bs{x}_{\uparrow}^{\text{old}})|^2\notag\\
\nabla_k\ln|\hat{D}_{\uparrow}|&=\sum_{j=1}^{M/2}\nabla_kd_{jk}d_{kj}^{-1}\\
\nabla_k^2\ln|\hat{D}_{\uparrow}|&=\sum_{j=1}^{M/2}\nabla_k^2d_{jk}d_{kj}^{-1}-\Big(\sum_{j=1}^{M/2}\nabla_kd_{ik}d_{ki}^{-1}\Big)^2\notag
\end{empheq}

\begin{empheq}[box={\mybluebox[5pt]}]{align}
&\quad\text{if}\quad k\geq F/2:\notag\\
\frac{|\Psi_{\text{new}}|^2}{|\Psi_{\text{old}}|^2}&=
|\hat{D}_{\downarrow}(\bs{x}_{\downarrow}^{\text{new}})|^2/|\hat{D}_{\downarrow}(\bs{x}_{\downarrow}^{\text{old}})|^2\notag\\
\nabla_k\ln|\hat{D}_{\downarrow}|&=\sum_{j=M/2}^{M}\nabla_kd_{jk}d_{kj}^{-1}\\
\nabla_k^2\ln|\hat{D}_{\downarrow}|&=\sum_{j=M/2}^{M}\nabla_k^2d_{jk}d_{kj}^{-1}-\Big(\sum_{j=M/2}^{M}\nabla_kd_{ik}d_{ki}^{-1}\Big)^2\notag
\end{empheq}

\subsection{NQS-Gaussian}
Now over to the real deal; the machine learning inspired wave function elements. The total NQS wave function, presented in equation \eqref{eq:NQSWF}, was decided split up in case we wanted to run them separately. The first part will henceforth be denoted as the NQS-Gaussian,
\begin{equation}
\Psi(\bs{x};\bs{a})=\exp(-\sum_{i=1}^M\frac{(x_i-a_i)^2}{2\sigma^2})
\end{equation}
while the last part will be denoted as the NQS-Jastrow and is presented in the next subsection. 

The derivatives of the NQS-Gaussian are similar to those of the simple Gaussian, they are therefore just listed up in equation \eqref{eq:NQSGaussian}.

\begin{empheq}[box={\mybluebox[5pt]}]{align}
\label{eq:NQSGaussian}
\frac{\Psi_{\text{new}}^2}{\Psi_{\text{old}}^2}&=\exp\Big((x_i^{\text{old}}+x_i^{\text{new}}-2a_i)(x_i^{\text{old}}-x_i^{\text{new}})\Big)\notag\\
\nabla_k\ln\Psi &= -\frac{x_k-a_k}{\sigma^2}\notag\\
\nabla_k^2\ln\Psi&=-\frac{1}{\sigma^2}\\
\partial_{a_l}\nabla_k\ln\Psi&=\frac{1}{\sigma^2}\notag\\
\partial_{a_l}\nabla_k^2\ln\Psi&=0\notag
\end{empheq}

\subsection{NQS-Jastrow Factor}
\begin{equation*}
J(\bs{x};\bs{b},\bs{W})=\prod_{j=1}^N\bigg[1+\exp\Big(b_j+\sum_{i=1}^M\frac{W_{ij}x_i}{\sigma^2}\Big)\bigg]
\end{equation*}

\begin{equation*}
\nabla_k \ln J=\sum_{j=1}^N\frac{W_{kj}}{\sigma^2}\frac{\exp\big(b_j+\sum_{i=1}^M\frac{W_{ij}x_i}{\sigma^2}\big)}{1+\exp\big(b_j+\sum_{i=1}^M\frac{W_{ij}x_i}{\sigma^2}\big)}
\end{equation*}

\begin{equation*}
\nabla_k^2 \ln J=\sum_{j=1}^N\frac{W_{kj}^2}{\sigma^4}\frac{\exp\big(b_j+\sum_{i=1}^M\frac{W_{ij}x_i}{\sigma^2}\big)}{\Big(1+\exp\big(b_j+\sum_{i=1}^M\frac{W_{ij}x_i}{\sigma^2}\big)\Big)^2}
\end{equation*}

\begin{equation*}
\partial_{b_l}\nabla_k \ln J=\frac{W_{kl}}{\sigma^2}\frac{\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)}{\Big(1+\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)\Big)^2}
\end{equation*}

\begin{equation*}
\partial_{b_l}\nabla_k^2 \ln J=\frac{W_{kl}^2}{\sigma^4}\frac{\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)\Big(1-\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)\Big)}{\Big(1+\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)\Big)^3}
\end{equation*}

\begin{equation*}
\partial_{W_{ml}}\nabla_k \ln J=\frac{1}{\sigma^2}\frac{\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)}{1+\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)}\delta_{mk}
+\frac{W_{kl}x_m}{\sigma^4}\frac{\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)}{\Big(1+\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)\Big)^2}
\end{equation*}

\begin{equation*}
\partial_{W_{ml}}\nabla_k^2 \ln J=2\frac{W_{kl}}{\sigma^4}\frac{\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)}{\Big(1+\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)\Big)^2}\delta_{mk}
+\frac{W_{kl}^2x_m}{\sigma^4}\frac{\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)}{\Big(1+\exp\big(b_l+\sum_{i=1}^M\frac{W_{il}x_i}{\sigma^2}\big)\Big)^3}
\end{equation*}
where $\delta_{ij}$ is the Kronecker delta. Defining 
\begin{equation*}
p_j\equiv \frac{1}{1+\exp\big(+b_j+\sum_{i=1}^M\frac{W_{ij}x_i}{\sigma^2}\big)}\quad\text{and}\quad n_j\equiv \frac{1}{1+\exp\big(-b_j-\sum_{i=1}^M\frac{W_{ij}x_i}{\sigma^2}\big)}
\end{equation*}
the expressions above can be simplified in the following fashion
\begin{empheq}[box={\mybluebox[5pt]}]{align}
\frac{J_{\text{new}}^2}{J_{\text{old}}^2}&=\prod_{j=1}^N\frac{p_j^{\text{old}}}{p_j^{\text{new}}}\notag\\
\nabla_k\ln J &=\sum_{j=1}^N\frac{W_{kj}}{\sigma^2}n_j\notag\\
\nabla_k^2\ln J &= \sum_{j=1}^N\frac{W_{kj}^2}{\sigma^4}p_jn_j\notag\\
\partial_{b_l}\nabla_k\ln J &=\frac{W_{kl}}{\sigma^2}p_ln_l\\
\partial_{b_l}\nabla_k^2\ln J &=\frac{W_{kl}^2}{\sigma^4}p_ln_l(p_l-n_l)\notag\\
\partial_{W_{ml}}\nabla_k\ln J &=\frac{1}{\sigma^2}n_l\delta_{mk}+\frac{W_{kl}x_m}{\sigma^4}p_ln_l\notag\\
\partial_{W_{ml}}\nabla_k^2\ln J &=2\frac{W_{kl}}{\sigma^4}p_ln_l\delta_{mk}+\frac{W_{kl}^2x_m}{\sigma^6}p_ln_l(p_l-n_l)\notag
\end{empheq}

\subsection{Hydrogen-Like Orbitals}
\begin{equation}
\Psi(\alpha, \bs{r})=\exp\Big[-\frac{1}{2}\alpha\sum_{i=1}^Nr_i\Big]
\end{equation}
where the derivative with respect to coordinate $r_k$ is
\begin{equation}
\nabla_k\ln\Psi(\alpha)=-\alpha
\end{equation}
and the second derivative is
\begin{equation}
\nabla_k^2\ln\Psi(\alpha)=0
\end{equation}
The gradients for those derivatives are
\begin{equation}
\partial_{\alpha} \nabla_k\ln\Psi(\alpha)=-1
\end{equation}
and
\begin{equation}
\partial_{\alpha} \nabla_k^2\ln\Psi(\alpha)=0
\end{equation}
respectively.  