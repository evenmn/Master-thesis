\chapter{Calculations of a general Gaussian-binary RBM wave function} \label{app:rbmderive}
In this appendix, we start from a general Gaussian-binary restricted Boltzmann machine and set up the system energy and joint probability distribution. 

The most basic Gaussian-binary restricted Boltzmann machine is the one on the form 
\begin{equation}
\begin{aligned}
E(\bs{x},\bs{h})&=\sum_{i=1}^{F}\frac{(x_i-a_i)^2}{2\sigma_i^2}-\sum_{j=1}^Hb_jh_j-\sum_{i,j=1}^{F,H}\frac{x_iw_{ij}h_j}{\sigma_i^2}\\
&=\sum_{i=1}^{F}\frac{(x_i-a_i)^2}{2\sigma_i^2}-\sum_{j=1}^Hh_j\Big(b_j+\sum_{i=1}^{F}\frac{x_iw_{ij}}{\sigma_i^2}\Big)
\end{aligned}
\end{equation}
as discussed in chapter \ref{chp:machinelearning}. If we now denote the expression in the last parenthesis by $f_j(\bs{x};\bs{\theta})$ where $\bs{\theta}$ includes all the parameters, we end up with the expression of the general Gaussian-binary restricted Boltzmann machine,
\begin{equation}
E(\bs{x},\bs{h})=\sum_{i=1}^{F}\frac{(x_i-a_i)^2}{2\sigma_i^2}-\sum_{j=1}^Hh_jf_j(\bs{x};\bs{\theta})
\end{equation}
where $f_j(\bs{x};\bs{\theta})$ in principle can be any function of $\bs{x}$ and $\bs{\theta}$. From this expression, we obtain the joint probability distribution
\begin{equation}
\begin{aligned}
P(\bs{x},\bs{h})&=\frac{1}{Z}\exp(-\beta E(\bs{x},\bs{h}))\\
&\propto\exp(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}) \exp(\sum_{j=1}^H\Big(h_jf_j(\bs{x};\bs{\theta})\Big))\\
&\propto\exp(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}) \prod_{j=1}^H\exp\Big(h_jf_j(\bs{x};\bs{\theta})\Big)
\end{aligned}
\end{equation}
where we set $\beta=1/k_BT=1$ and we ignore the partition function $Z$. Our main interest is the marginal distribution, which we will derive in detail.

\section{Marginal probability}\label{sec:derive}
In chapter \ref{chp:machinelearning}, we presented the marginal distribution of the visible nodes as 
\begin{equation}
P(\bs{x})=\sum_{\bs{h}}P(\bs{x},\bs{h})
\end{equation}
which for our function is 
\begin{equation}
\begin{aligned}
P(\boldsymbol{x})&\propto\sum_{\{\boldsymbol{h}\}}\exp\Big(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}\Big) \prod_{j=1}^H\exp\Big(h_jf_j(\bs{x},\bs{\theta})\Big)\\
&=\sum_{h_1=0}^1\sum_{h_2=0}^1\hdots\sum_{h_H=0}^1\exp\Big(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}\Big)\exp\Big(h_1f_1\Big)\exp\Big(h_2f_2\Big)\hdots\exp\Big(h_Hf_H\Big)\\
&=\exp\Big(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}\Big)\sum_{h_1=0}^1\sum_{h_2=0}^1\hdots\sum_{h_H=0}^1\exp\Big(h_1f_1\Big)\exp\Big(h_2f_2\Big)\hdots\exp\Big(h_Hf_H\Big)\\
&=\exp\Big(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}\Big)\sum_{h_1=0}^1\exp\Big(h_1f_1\Big)\sum_{h_2=0}^1\exp\Big(h_2f_2\Big)\hdots\sum_{h_H=0}^1\exp\Big(h_Hf_H\Big)\\
&=\exp\Big(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}\Big)\prod_{j=1}^H\sum_{h_j=0}^1\exp\Big(h_jf_j\Big)\\
&=\exp\Big(\sum_{i=1}^F \frac{(x_i - a_i)^2}{2\sigma^2}\Big) \prod_{j=1}^H \bigg[1+ \exp\Big(f_j(\bs{x};\bs{\theta})\Big)\bigg]
\end{aligned}
\end{equation}
where we utilize that only an element in the product contains a certain hidden node $h_j$.

\section{Gradient of wave function and log-likelihood function} \label{sec:derivatives}
Defining the wave function as the marginal probability, we have seen that wave function of a general Gaussian-binary restricted Boltzmann machine has the form
\begin{equation}
\psi(\bs{x};\bs{a},\bs{\theta})=\exp(-\sum_{i=1}^{F}\frac{(x_i-a_i)^2}{2\sigma^2})\prod_{j=1}^H\Big[1+\exp(f_j(\bs{x};\bs{\theta}))\Big]
\end{equation}
where $f_j(\bs{x};\bs{\theta})$ is an arbitrary function of the coordinates $\bs{x}$ and the weights $\bs{\theta}$. The Gaussian part is straight-forward to differentiate, so we will keep our attention on the product,
\begin{equation}
\psi_{\text{p}}(\bs{x};\bs{\theta})=\prod_{j=1}^H\Big[1+\exp(f_j(\bs{x};\bs{\theta}))\Big].
\end{equation}
Henceforth, we will omit the variable $\bs{x}$ and $\bs{\theta}$. By introducing the functions
\begin{equation}
p_j\equiv \frac{1}{1+\exp(+f_j)}\quad\wedge\quad n_j\equiv \frac{1}{1+\exp(-f_j)},
\end{equation}
where the last one is the sigmoid function, we find the gradient and Laplacian of $\ln\psi_{\text{p}}$ to be
\begin{equation}
\nabla_k\ln\psi_{\text{p}}=\sum_{j=1}^Hn_j\nabla_k(f_j)
\end{equation}
and
\begin{equation}
\nabla_k^2\ln\psi_{\text{p}}=\sum_{j=1}^Hn_j\big[\nabla_k^2(f_j)+p_j\big(\nabla_k(f_j)\big)^2\big]
\end{equation}
respectively. The parameter $\theta_i$ can be updated according to the following rule
\begin{equation}
\frac{\partial}{\partial \theta_i}\ln \psi_{\text{p}}=\sum_{j=1}^Hn_j\frac{\partial}{\partial\theta_i}(f_j).
\end{equation}
and the ratio between wave functions can be found by
\begin{equation}
\frac{\psi_{\text{p}}^{\text{new}}}{\psi_{\text{p}}^{\text{old}}}=\prod_{j=1}^H\frac{p_j^{\text{old}}}{p_j^{\text{new}}}.
\end{equation}
As a conclusion, what we actually need to calculate to find respective expressions for each wave function is $\nabla_k(f_j)$, $\nabla_k^2(f_j)$ and $\partial_{\theta_i}(f_j)$.This applies for a general Gaussian-binary restricted Boltzmann machine, also for a deep Boltzmann machine if all the units are Gaussian-binary.