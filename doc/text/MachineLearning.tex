\chapter{Machine Learning}
Parameter estimation is a large part of science, because we are often not able to measure things directly. For instance, when Millikan in ... performed his famous electron charge experiment or when we estimate Sun's mass. 

Sometimes when people talk about machine learning, it sounds like its a totally new field, but the truth is that many techniques that used to have other names, are now classified as machine learning. As the UiO professor Anne Solberg said during one of her lectures

''In the early 1990's I was working a lot with machine learning, but at that time we called it pattern recognition and regression''

Machine learning includes all methods where we want to fit a model to a data set, and pattern recognition and regression are clearly some of those methods. In both cases we have concrete targets for the training, and the training is therefore called supervised training. In other cases we do not have targets, but want to train our model based on a probability distribution or so, which is called unsupervised learning.

\section{Supervised Learning}
Regression, pattern recognition, 
Feed-forward neural networks, 

\section{Unsupervised Learning}
How can we train using unsupervised learning?

\subsection{Statistical foundation}
Bayesian statistics

\subsection{Boltzmann Machines}
Based on a Hopfield network
How the things are derived, including Boltzmann distribution and stuff from statistical mechanics 

\subsection{Restricted Boltzmann Machines}