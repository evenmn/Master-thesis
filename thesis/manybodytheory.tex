\chapter{Many-body Quantum Mechanics} \label{chp:manybody}
\epigraph{We have to remember that what we observe is not nature in itself but
	nature exposed to our method of questioning.}{Werner Heisenberg, \supercite{heisenberg_across_1990}}
\begin{figure}[H]
	\centering
	\captionsetup[subfigure]{labelformat=empty}
	\copyrightbox[l]{\includegraphics[scale=3]{../Images/art_quantum.jpg}}{Physical review letters,\\ 110, 213001 (2013)}
	\caption{The first photograph of a hydrogen atom was captured by an ultra sensitive camera in 2013. One can actually see the probability distribution $|\Psi(\bs{x})|^2$ with the naked eye. Published by \citet{stodolna_hydrogen_2013} with the title \textit{Hydrogen atoms under magnification}.}
\end{figure}

\sloppy
In the previous chapter, quantum mechanics of single particles was discussed. We presented the time-independent SchrÃ¶dinger equation, and from that, we obtained a general expression for the energy of a stationary particle. The energy expression of a stationary many-particle system is almost identical and given by
\begin{equation}
E_n=\mel{\Psi_n(\bs{X})}{\hat{\mathcal{H}}}{\Psi_n(\bs{X})}
\label{eq:energy}
\end{equation}
where we have used the dirac formalism \supercite{dirac_new_1939}. However, here we use the many-body wave function $\Psi_n(\bs{X})$ of state $n$ with $\bs{X}=\{\bs{x}_1,\bs{x}_2,\cdots,\bs{x}_N\}=\{\{\bs{r}_1, \sigma_1\}, \{\bs{r}_2, \sigma_2\},\cdots,\{\bs{r}_N, \sigma_N\}\}$ denoting the collective coordinates, again including the positions and spins, of all the $N$ particles in the system. The Hamiltonian, $\hat{\mathcal{H}}$, defines the system and is given explicitly in the next section. As noted before, the wave function of large systems needs to store an immense amount of information and is therefore impractical or even impossible to deal with. In this section, we will first look at how the many-body Hamiltonian is composed, before we have an extensive discussion of how the many-body wave function is constructed.

\section{The electronic Hamiltonian} \label{sec:electronichamiltonian}
We have already seen what the one-body Hamiltonian looks like, and the many-body Hamiltonian is not very different. We recall that it can be split in a kinetic and a potential term,
\begin{equation}
\hat{H}=\hat{T}+\hat{V},
\end{equation}
where $\hat{T}$ is the kinetic energy and $\hat{V}$ is the potential energy. Nevertheless, as we study electrons, they are charged and will therefore interact with each other. For that reason, we need to add an interaction term to the Hamiltonian, which in general is included in the potential term $\hat{V}=\hat{V}_{\text{ext}}+\hat{V}_{\text{int}}$ with $\hat{V}_{\text{ext}}$ as the external potential and $\hat{V}_{\text{int}}$ as the interaction potential. In the same way as the nucleus-electron potential, the interaction potential is given by Coulomb's law, for two electrons given by 
\begin{equation}
\hat{V}_{\text{int}} =k_e\frac{e^2}{r_{12}},
\end{equation}
where $r_{12}$ is the distance between the electrons. For a general system containing $N$ electrons, the total Hamiltonian can therefore be expressed as 
\begin{empheq}[box={\mybluebox[5pt]}]{equation}
\hat{\mathcal{H}}=-\sum_{i=1}^N\frac{\hbar^2}{2m_e}\nabla_i^2+\sum_{i=1}^{N}V_{\text{ext}}(x_i) + \sum_{i=1}^N\sum_{j>i}^Nk_e\frac{e^2}{r_{ij}},
\label{eq:ElectronicHamiltonian}
\end{empheq}
without specifying the external potential, $V_{\text{ext}}$. The relative distance between particles $i$ and $j$ is defined by $r_{ij}\equiv|\bs{r}_i-\bs{r}_j|$. From now on, we will use atomic units setting $\hbar=m_e=k_e=e=1$, see appendix \ref{app:units} for details.

By inserting the Hamiltonian in equation \eqref{eq:ElectronicHamiltonian} into equation \eqref{eq:energy}, the integral can be split in three terms,
\begin{equation}
\begin{aligned}
E_n&=\sum_{i=1}^N\bigg[-\frac{1}{2}\mel{\Psi_n(\bs{X})}{\nabla_i^2}{\Psi_n(\bs{X})}
+\mel{\Psi_n(\bs{X})}{V_{\text{ext}}(x_i)}{\Psi_n(\bs{X})}
+\sum_{j>i}^N\mel{\Psi_n(\bs{X})}{\frac{1}{r_{ij}}}{\Psi_n(\bs{X})}\bigg],
\end{aligned}
\end{equation}
where the two former terms are the one-body integrals, or \textit{matrix elements}, which in many cases can be solved analytically. However, the last term is often difficult to solve, and in fact there are analytical solutions available for the two-particle case only. In other words, a precise evaluation of this integral can usually only be found using numerical methods, which we will take a closer look at in chapter \ref{chp:methods} in conjunction with quantum Monte Carlo methods.

\section{The many-body wave function} \label{sec:wavefunction}
By the first postulate of quantum mechanics presented in section \ref{sec:postulates}, the wave function contains all the information specifying the state of the system. This means that all observables in classical mechanics can in principle also be estimated from the wave function, implying that finding the wave function is the main goal. As discussed in chapter \ref{chp:quantum}, we can define the wave function for a single particle, known as the \textit{single-particle function} (SPF), $\psi(\bs{r},\sigma)$. Can we combine the SPFs of the electrons in a system and obtain the many-body wave function? Possibly, the most straightforward way of doing this is to simply multiply all the SPFs,
\begin{equation}
\Psi(\bs{X})=\psi(\bs{r}_1,\sigma_1)\psi(\bs{r}_2,\sigma_2)\cdots\psi(\bs{r}_N,\sigma_N),
\end{equation}
known as the \textit{Hartree product}. However, this product is generally not correct, as it does not include the required symmetry properties of the many-body wave function. Instead, we can account for the symmetry by expressing the many-body wave function as a determinant or a permanent, as we will see in section \ref{sec:slater}. Together with the symmetry properties, there is an array of requirements the wave function needs to meet in order to be physically correct. Some of them are:

\iffalse
We will in this section discuss the symmetry properties of the wave function for bosonic and fermionic systems, and see how the wave function can be set up as a Slater determinant in order to meet these properties. Also, Jastrow factors will be touched, as they are used in quantum Monte Carlo methods to handle the correlations. With that in mind, we approximate the \textit{trial} wave function by a Slater-Jastrow function,
\begin{equation}
\Psi_T(\bs{r};\bs{\theta})=|\hat{D}(\bs{r};\bs{\theta})|J(\bs{r};\bs{\theta}),
\end{equation}
which is an educated guess of the form of the wave function. 
Here the first part, $|\hat{D}(\bs{r};\bs{\theta})|$, is the Slater determinant and $J(\bs{r};\bs{\theta})$ is a Jastrow factor with $\theta$ as some variational parameters. Other quantum many-body methods, such as full configuration interaction and coupled cluster use a linear expansion of Slater determinants to approximate the wave function, while the Hartree-Fock method relies on one single Slater determinant (without any Jastrow factor). Nevertheless, as we will focus on quantum Monte Carlo methods, this chapter will be tailored to the method. 

The trial wave function needs to satisfy some requirements in order to be used in the variational principle, and we thus need to make an educated guess on the wave function where the requirements are fulfilled. The requirements are the following:
\fi

\begin{enumerate}
	\item \textbf{Normalizability:} The wave function needs to be normalizable in order to make physical sense. The total probability should always be 1, and a wave function that cannot be normalized will not have a finite total probability. The consequence is that the wave function goes to zero when the positions get large, $\Psi(x\rightarrow\pm\infty)\rightarrow 0$. 
	
	\item \textbf{Cusp condition:} From electrostatics, we know that identical, charged particles will repulse each other. This means that the probability of finding two particles close together should be low, which needs to be included in the wave function. The reduction of the wave function due to an electron-electron pair is called an electron-electron cusp. Also nucleon-electron pairs and nucleon-nucleon pairs cause wave function cusps, and they are all subject to the cusp condition.
	
	\item \textbf{Symmetry and anti-symmetry:} The wave function needs to be either symmetric or anti-symmetric under the exchange of two coordinates, depending on whether the electrons are fermions or bosons. This is the statement of the sixth postulate, which will be further explained in the next section.
\end{enumerate}

\subsection{Anti-symmetry and the Pauli principle} \label{sec:symmetry}
Symmetry and anti-symmetry are central concepts in quantum mechanics, and often one can use symmetry arguments to simplify expressions and calculations. Assume that we have a permutation operator, $\hat{P}(i\rightarrow j)$, which exchanges the coordinates of the particles $i$ and $j$ in the many-body wave function. With $M$ particles, the mathematical operation can be described by
\begin{equation}
\hat{P}(i\rightarrow j)\Psi_n(\bs{x}_1,\cdots,\bs{x}_i,\cdots,\bs{x}_j,\cdots,\bs{x}_M)=p\Psi_n(\bs{x}_1,\cdots,\bs{x}_j,\cdots,\bs{x}_i,\cdots,\bs{x}_M),
\end{equation}
where $p$ is the eigenvalue coming from the transformation. If we again apply the $\hat{P}$ operator, we should switch the same coordinates back, and we expect to end up with the initial wave function. For that reason, $p$ must be either +1 or -1 \footnote{Actually, in two-dimensional systems a third possibility is allowed which gives an \textit{anyon}. The theory on this was developed by \citet{leinaas_one_1977} during the 1970s.}. The particles that have an anti-symmetric wave function under the exchange of two coordinates are called fermions, named after Enrico Fermi, and as discussed before, they have half-integer spin. On the other hand, the particles that have a symmetric wave function under the exchange of two coordinates are called bosons, named after Satyendra Nath Bose, and have integer spin. A consequence of the anti-symmetric wave function is that two identical fermions cannot occupy the same single-particle state, known as the Pauli principle. This means that identical fermions even in the many-particle ground state (at zero temperature) spread over multiple states, and in the next section, we will see how this principle is included in the wave function through a Slater determinant. 

\subsection{The Slater determinant} \label{sec:slater}
For a system of many particles, we can define a many-body wave function, which is a composition of all the SPFs and contains all the information about the system as the 1st postulate requires. For fermions, we need to combine the SPFs such that the Pauli principle is fulfilled at all times, which can be accomplished by a determinant. 

Consider a system of two identical fermions with SPFs $\psi_1(\bs{r},\sigma)$ and $\psi_2(\bs{r},\sigma)$ of coordinates $\{\boldsymbol{r}_1,\sigma_1\}$ and $\{\boldsymbol{r}_2,\sigma_2\}$, respectively. The way we define the many-body wave function is then
\begin{equation}
\begin{aligned}
\Psi(\bs{X})&=\frac{1}{\sqrt{2}}
\begin{vmatrix}
\psi_1(\boldsymbol{r}_1,\sigma_1) & \psi_2(\boldsymbol{r}_1,\sigma_1)\\
\psi_1(\boldsymbol{r}_2,\sigma_2) & \psi_2(\boldsymbol{r}_2,\sigma_2)
\end{vmatrix},\\
&=\frac{1}{\sqrt{2}}\Big[\psi_1(\boldsymbol{r}_1,\sigma_1)\psi_2(\boldsymbol{r}_2,\sigma_2)-\psi_2(\boldsymbol{r}_1,\sigma_1)\psi_1(\boldsymbol{r}_2,\sigma_2)\Big],
\end{aligned}
\end{equation}
which is zero if the particles happen to have the same quantum numbers. If the particles, on the other hand, have different spins, they are allowed to appear at the same spatial state at the same time and the determinant will not equate to zero. For larger systems, the Slater determinant is constructed in the same way as above, and any pair of identical particles located in the same state will make the determinant collapse. A Slater determinant containing $N$ electrons reads
\begin{equation}
\Psi(\bs{X})=\frac{1}{\sqrt{N!}}
\begin{vmatrix}
\psi_1(\boldsymbol{r}_1,\sigma_1) & \psi_2(\boldsymbol{r}_1,\sigma_1) & \cdots & \psi_N(\boldsymbol{r}_1,\sigma_1)\\
\psi_1(\boldsymbol{r}_2,\sigma_2) & \psi_2(\boldsymbol{r}_2,\sigma_2) & \cdots & \psi_N(\boldsymbol{r}_2,\sigma_2)\\
\vdots & \vdots & \ddots & \vdots \\
\psi_1(\boldsymbol{r}_N,\sigma_N) & \psi_2(\boldsymbol{r}_N,\sigma_N) & \cdots & \psi_N(\boldsymbol{r}_N,\sigma_N)
\end{vmatrix},
\end{equation}
where the $\psi(\bs{r},\sigma)$ is the tensor product between the radial part $\phi(\bs{r})$ and the spin part $\xi(\sigma)$,
\begin{equation}
\psi(\bs{r},\sigma)=\phi(\bs{r})\otimes\xi(\sigma).
\end{equation}
In section \ref{sec:slaterdeterminant}, we show that the Slater determinant can be split in a spin-up and a spin-down part with the assumption that the Hamiltonian is spin-independent. From this, it follows that the spin-dependency, $\xi(\sigma)$, can be omitted. For that reason, we can define a basis set depending on the spatial coordinates only.

As a side note, we will in the rest of this thesis use $\Psi$ as the many-particle wave function, $\psi$ are the SPFs, and $\phi$ is the spatial part of the SPF. We reserve $\xi$ for the spin part of the SPFs, but it will often be omitted as the spin-part can be factorized out of the wave function. Sometimes it is appropriate to split up the many-particle wave function, and we will, in that case, denote each part by $\Psi_i$ where $i$ is an index associated with the particular element. Lastly, the basis functions will be denoted by $\varphi$, which we will discuss in the next section.

\subsection{Basis set} \label{sec:basisset}
In quantum chemistry, a basis set usually refers to a set of one-particle functions used to build the SPFs discussed above. The basis functions depict the eigenstates of atoms, and are therefore often called \textit{atomic orbitals}. On the other hand, the SPFs are linear combinations of the atomic orbitals suited for describing the the wave-like behavior of an electron in a molecule, hence named \textit{molecular orbitals}. Commonly used atomic orbitals are Pople basis sets \supercite{ditchfield_self-consistent_1971} (in the form of x-yz G), correlation-consistent basis sets \supercite{dunning_gaussian_1989} (in the form of cc-pVNZ) and Slater-type orbitals \supercite{slater_atomic_1930} (in the form of STO-nG), where all are built on Gaussian functions. Gaussian functions are preferred as they allow efficient implementations of post Hartree-Fock methods, defined as the methods developed to improve on the Hartree-Fock method.

In our work, however, the molecular orbitals correspond to the basis functions, as we in most of the cases do not expand our SPFs, $\psi(\bs{r},\sigma)$, in a basis set. Our SPFs are typically the solution of the non-interacting system, and as the Jastrow factor is supposed to deal with the interaction, we use the same functions for the interacting case as well.

A common notation is to use the Greek letter $\varphi$ for the atomic orbitals and $\psi$ for the molecular orbitals, such that single-particle functions can be obtained from an expansion of the $N$ basis functions $\{\varphi_1(\bs{r}),\varphi_2(\bs{r}),\cdots\varphi_N(\bs{r})\}$ in the manner of
\begin{equation}
\psi_i(\bs{r})=\sum_{j=1}^Nc_{ji}\varphi_j(\bs{r}),
\label{eq:expansion}
\end{equation}
where $c_{ij}$ are the coefficients to be found. There are different approaches to obtain these coefficients, where the popular Hartree-Fock algorithm generates $c_{ij}$'s in order to find the optimal Slater determinant. For a larger basis, the results will be more accurate, but at an increasing computational cost \supercite{daniel_crawford_introduction_2007}. The actual functions used in this work are presented in chapter \ref{chp:systems} and they are linked to their respective systems. 

\subsection{Modeling the cusp} \label{sec:cusp}
According to Coulomb's law, particles of the same charge repeal each other, and particles of opposite charge attract each other. For an interacting system, this will affect the wave function. An electron-electron pair causes a pit in the wave function, while a electron-nucleon pair causes a peak in the wave function. These interaction-caused shapes of the wave functions are called cusps, and are subject to the cusp condition. In general, it provides a relation between the wave function and the slope of the wave function when we approach the cusp,
\begin{equation}
\frac{\partial\Psi(\bs{R})}{\partial r_{\alpha\beta}}\bigg|_{r_{\alpha\beta}=0}=\Psi(\bs{R})f(r_{\alpha\beta})
\end{equation}
where $r_{\alpha\beta}$ is the distance between two particles $\alpha$ and $\beta$, and $f(r_{\alpha\beta})$ is a function dependent on the particles types \supercite{bingel_a_physical_1967}.

Different methods address this challenge in different ways. The Hartree-Fock method attempts to construct an optimal single Slater determinant by expanding the molecular orbitals in atomic orbitals, like shown in equation \eqref{eq:expansion}. These coefficients can be obtained using for example the Hartree-Fock algorithm \supercite{hartree_wave_1928, fock_selfconsistent_1930}. Then, we only need to deal with a Slater determinant, and as the correlations are not given explicitly, the Hartree-Fock theory is often called a mean-field theory. Further, we have post Hartree-Fock methods, like configuration interaction theory and the coupled cluster method. Both methods utilize the Hartree-Fock basis, but express the wave function as a linear combination of Slater determinants, where the correlations are determined by the coefficients \supercite{daniel_crawford_introduction_2007}. If a sufficient number of Slater determinants are included in the linear combination, both methods are capable of providing exact results. However, since the methods are computationally intensive, this is possible only for very small systems.

The variational Monte Carlo (VMC) method, which we have implemented in this work, models the electron-electron cusp in a totally different way. We there define a \textit{trial wave function}, which consists of one or more Slater determinants and a Jastrow factor, where the latter is assumed to account for the correlations. The Jastrow factor will be discussed further in section \ref{sec:jastrow}.

\section{Electron density} \label{sec:electrondensity}
In quantum many-body computations, the electron density is frequently calculated, and there are several reasons for that. First, the electron density can be found experimentally, such that the calculations can be benchmarked. Second, the electron density is very informative, since information about all particles can be gathered in a plot. In this work we will limit us to the one-body density denoted by $\rho_1(\bs{r}_i)$ and the two-body density denoted by $\rho_2(\bs{r}_i, \bs{r}_j)$. They are given by
\begin{empheq}[box={\mybluebox[5pt]}]{equation}
\label{eq:onebody_density}
\rho_1(\bs{r}_i)=N\int_{-\infty}^{\infty}d\bs{r}_{1}\cdots d\bs{r}_{i-1}d\bs{r}_{i+1}\cdots d\bs{r}_N |\Psi(\bs{r}_1,\cdots \bs{r}_N)|^2
\end{empheq}
and
\begin{empheq}[box={\mybluebox[5pt]}]{equation}
\label{eq:twobody_density}
\rho_2(\bs{r}_i, \bs{r_j})=N\int_{-\infty}^{\infty}d\bs{r}_{1}\cdots d\bs{r}_{i-1}d\bs{r}_{i+1}\cdots d\bs{r}_{j-1}d\bs{r}_{j+1}\cdots d\bs{r}_N |\Psi(\bs{r}_1,\cdots \bs{r}_N)|^2,
\end{empheq}
respectively. \iffalse The $P$-body electron density is defined by the multi-dimensional integral over the probability density function of all the particles but $P$, for a normalized wave function represented by
\begin{empheq}[box={\mybluebox[5pt]}]{equation}
\label{eq:electron_density}
\rho_P(\bs{r}_1,\cdots,\bs{r}_P)=N\int_{-\infty}^{\infty}d\bs{r}_{P+1}\cdots d\bs{r}_N |\Psi(\bs{r}_1,\cdots \bs{r}_N)|^2,
\end{empheq}
where $P\leq N$.\fi These integrals are in general difficult to solve, and they can be found analytically for just a few realistic systems. For other systems, we need to solve the integral numerically, and we will in chapter \ref{chp:methods} describe how this can be done using Monte Carlo integration. As we cannot pinpoint a particle in quantum mechanics, i.e. it is impossible to distinguish two identical particles in any way, the electron density is the same irrespective of which particle we decide to leave out. 

The density should not be normalized to unit both when it is calculated analytically and numerically, but to the number of particles, given by
\begin{equation}
\int_{-\infty}^{\infty}d\bs{r}_{1}\cdots d\bs{r}_{i-1}d\bs{r}_{i+1}\cdots d\bs{r}_N\Big[\rho_P(\bs{r}_1,\cdots,\bs{r}_P)\Big]=N
\end{equation}
for the one-body density.

Which physical information can we read from the electron density? The one-body density, is sometimes simply referred to as the electron density. It gives the probability density of finding an electron throughout the space, and give insight about how the particles are distributed in the system. On the other hand, the two-body density becomes a two-dimensional function and is therefore often expressed as a matrix. It gives the probability density of finding an electron throughout the space, given the coordinates of another particle. It, therefore, contains information about how the particles distribute relative to each other and is essential when we want to study the pairwise interaction. In systems where the strong nucleon force is important, the three-body interactions are essential. Then, calculating the three-body density, $\rho_3(\bs{r}_i, \bs{r}_j, \bs{r}_k)$, also gives useful insight about the system. For closed-shell circular quantum dots, the radial electron density profile is often preferred as the density then also is circular and independent of the angle. 

For non-interacting systems, the wave function is separable with respect to the different particles. In these cases we can easily find the electron density analytically, since the single-particle functions of the particles that we do not integrate over can be taken out of the integral. Represented by the one-body density, 
\begin{equation}
\begin{aligned}
\rho_1(\bs{r}_i)&=\int_{-\infty}^{\infty}d\bs{r}_{1}\cdots d\bs{r}_{i-1}d\bs{r}_{i+1}\cdots d\bs{r}_N |\Psi(\bs{r}_1),\cdots \Psi(\bs{r}_N)|^2,\\
&=\int_{-\infty}^{\infty}d\bs{r}_{1}\cdots d\bs{r}_{i-1}d\bs{r}_{i+1}\cdots d\bs{r}_N |\Psi(\bs{r}_1)|^2\cdots |\Psi(\bs{r}_N)|^2,\\
&=|\Psi(\bs{r}_i)|^2\underbrace{\int_{-\infty}^{\infty}d\bs{r}_{1}|\Psi(\bs{r}_{1})|^2}_{=1}\cdots\underbrace{\int_{-\infty}^{\infty}d\bs{r}_{i-1}|\Psi(\bs{r}_{i-1})|^2}_{=1}\underbrace{\int_{-\infty}^{\infty}d\bs{r}_{i+1}|\Psi(\bs{r}_{i+1})|^2}_{=1}\cdots\underbrace{\int_{-\infty}^{\infty}d\bs{r}_{N}|\Psi(\bs{r}_{N})|^2}_{=1},\\
&=|\Psi(\bs{r}_i)|^2,
\end{aligned}
\end{equation}
where we have assumed that the wave functions are normalized. This result has no scientific importance, but will be used to validate the implementation of the electron density in the code, see section \ref{sec:norepulsive}.

\subsection{Wigner crystals} \label{sec:wigner}
A Wigner crystal is a solid phase where electrons maximize the distance to each other in order to minimize the potential energy. As Coulomb's law gives the interaction potential, the potential is minimized when the distances between the electrons are maximized. In one-dimensional systems, the electrons are thus found at discrete locations, such that they form an evenly spaced lattice. In two-dimensional systems, the Wigner crystals form triangular lattices which are known to be the configuration that maximizes the distance in a limited space, and in three-dimensional systems, the electrons form so-called body-centered cubics. The phenomenon occurs only when the potential energy dominates the kinetic energy since the electrons then are almost "at rest" and external forces are not strong enough to push the electrons close to each other.


