\chapter{Dirac Formalism} \label{app:dirac}
The Dirac formalism, also called bracket notation, was suggested by \citet{dirac_new_1939} in a 1939 paper to improve the reading ease. The notation unites the integral representation and the matrix representation in an elegant fashion by representing all elements in the \textit{Hilbert-space}. 

The Hilbert-space is a complete linear vector space, which allows length, inner products and angles between vectors to be measured. A column vector in the space is denoted by $\ket{\psi}$, which is called the \textit{ket}, and by taking the Hermitian conjugate of it we obtain the corresponding row vector, $(\ket{\psi})^+=\bra{\psi}$ called the \textit{bra}. As the Hilbert-space is characterized by linearity, it requires that the sum of two element in the space is also an element in the space,
\begin{equation}
\ket{\psi_1}+\ket{\psi_2}=\ket{\psi_1+\psi_2},
\end{equation}
and that two elements always \textit{commute},
\begin{equation}
\ket{\psi_1}+\ket{\psi_2}=\ket{\psi_2}+\ket{\psi_1}.
\end{equation}
Another important property is that an element of the space multiplied with a complex number is also an element of the space,
\begin{equation}
c\ket{\psi}=\ket{c\psi}\quad\quad\forall\quad c\in\mathbb{C}.
\end{equation}

To fully utilize the notation, orthogonality properties need to be taken into account. Assume that we have a orthogonal basis set 
\begin{equation}
\{\psi_1,\psi_2,\hdots,\psi_n\}.
\end{equation}
The inner product between two basis elements is then given by
\begin{equation}
\braket{\psi_i}{\psi_j}=
\begin{cases}
\neq 0\quad&\text{if}\quad i=j\\
=0\quad&\text{otherwise}
\end{cases}
\quad\equiv\delta_{ij}
\end{equation}
where we have introduced the Kronecker delta $\delta_{ij}$. If we further require that our basis is \textit{orthonormal}, the inner product is 1, and we can prove the \textit{completeness relation}. Assume we want to expand a vector $\ket{\chi}$ in our orthonormal basis set,
\begin{align}
\ket{\chi}&=\sum_{i=1}^nc_i\ket{\psi_i}.
\end{align}
By multiplying with one of the basis vectors on the left hand side, the sum collapses, and we are just left with one of the coefficients $c_j$,
\begin{align}
\braket{\psi_j}{\chi} &= \sum_{i=1}^nc_i\braket{\psi_j}{\psi_i}=c_j.
\end{align}
If we now again insert this into the expansion, we obtain
\begin{equation}
\ket{\chi}=\sum_{i=1}^n\underbrace{\braket{\psi_i}{\chi}}_{c_i}\ket{\psi_i}=\bigg[\sum_{i=1}^n\ket{\psi_i}\bra{\psi_i}\bigg]\ket{\chi}
\end{equation}
which implies that the outer product is equal to 1 (vectorized equal to the identity matrix),
\begin{equation}
\sum_{i=1}^n\ket{\psi_i}\bra{\psi_i}=1.
\end{equation}

We can use these properties to demonstrate how the normalization constant can be obtained without explicitly solving any integrals. Consider two spin-1/2 particles, for example the electron and the proton in the ground state of Hydrogen. There are then four possible states: the \textit{triplet} with $s=1$ and the \textit{singlet} with $s=0$. The latter reads \cite{griffiths_introduction_2005}
\begin{equation}
\ket{00}=A\big(\ket{\uparrow\downarrow}-\ket{\downarrow\uparrow}\big)
\end{equation}
which is associated with the bra
\begin{equation}
\bra{00}=\big(\ket{00}\big)^+=A\big(\bra{\uparrow\downarrow}-\bra{\downarrow\uparrow}\big).
\end{equation}
The inner product is then given by
\begin{equation}
\begin{aligned}
\braket{00}{00}&=A\big(\bra{\uparrow\downarrow}-\bra{\downarrow\uparrow}\big)A\big(\ket{\uparrow\downarrow}-\ket{\downarrow\uparrow}\big)\\
&=A^2\big(\braket{\uparrow\downarrow}{\uparrow\downarrow}-\braket{\uparrow\downarrow}{\downarrow\uparrow}-\braket{\downarrow\uparrow}{\uparrow\downarrow}+\braket{\downarrow\uparrow}{\downarrow\uparrow}\big)\\
&=A^2\big(1-0-0+1\big)\\
&=2A^2=1
\end{aligned}
\end{equation}
where we have assumed that also the states $\ket{\uparrow\downarrow}$ and $\ket{\downarrow\uparrow}$ are orthonormal. From this, we can see that the normalization constant $A$ must be equal to $1/\sqrt{2}$.

Further, we also use the Dirac notation as a short-hand notation of the Slater determinant, discussed in section \ref{sec:slater}. Instead of writing out the entire determinant, it is common to write it as
\begin{equation}
\ket{\psi_1\psi_2,\hdots,\psi_N}\equiv\frac{1}{\sqrt{N!}}
\begin{vmatrix}
\psi_1(\boldsymbol{r}_1,\sigma_1) & \psi_2(\boldsymbol{r}_1,\sigma_1) & \hdots & \psi_n(\boldsymbol{r}_1,\sigma_1)\\
\psi_1(\boldsymbol{r}_2,\sigma_2) & \psi_2(\boldsymbol{r}_2,\sigma_2) & \hdots & \psi_N(\boldsymbol{r}_2,\sigma_2)\\
\vdots & \vdots & \ddots & \vdots \\
\psi_1(\boldsymbol{r}_N,\sigma_N) & \psi_2(\boldsymbol{r}_N,\sigma_N) & \hdots & \psi_N(\boldsymbol{r}_N,\sigma_N)
\end{vmatrix}
\end{equation}
which is extensively used in for instance second quantization. This should not be confused with the Hartree product. 