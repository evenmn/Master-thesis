\chapter{Introduction}
Quantum mechanical laws determine the properties and behavior of quantum many-body systems, and have been known since the 1930s. The time-dependent Schrödinger equation describes the binding energy of atoms and molecules, as well as the interaction between particles in a gas. Moreover, it has been used to determine the energy of artificial structures like quantum dots \supercite{reimann_electronic_2002}, nanowires \supercite{wang_a_three_2004} and ultracold condensates \supercite{dubois_bose-einstein_2001}. Since quantum mechanics is one of the most precisely tested theories in the history of science \supercite{odom_new_2006}, computer experiments are in principle capable of obtaining the energy as precisely as laboratory experiments, and can in that sense replace laboratory experiments.

Although we know the laws of quantum mechanics, we encounter many challenges when calculating real-world problems. Firstly, interesting systems often involve a large number of particles. This causes expensive calculations. Secondly, the correct wave functions are seldom known for complex systems. Together, they contribute to the many-body problem.

\section{The many-body problem}
In quantum mechanics, a many-body system contains three or more interacting particles. These interactions create so-called quantum correlations, which make the wave function of the system a complicated object holding a large amount of information. As a consequence, exact or analytical calculations become impractical or even impossible. This is known as the many-body problem. Indeed, Paul Dirac recognized these problems already in 1929:

\begin{shadequote}{
		The general theory of quantum mechanics is now almost complete... ...The underlying physical laws necessary for the mathematical theory of a large part of physics and the whole of chemistry are thus completely known, and the difficulty is only that the exact application of these laws leads to equations much too complicated to be soluble. \par Paul M. Dirac, \emph{Quantum Mechanics of Many-electron Systems} \supercite{dirac_paul_adrien_maurice_quantum_1929}}
\end{shadequote}

There are numerous approaches to overcome this problem, where approximative methods often are used to reduce the, sometimes extreme, computational cost. Popular methods include the Hartree-Fock method, which replaces the interaction by a mean-field \supercite{hartree_wave_1928, fock_selfconsistent_1930}, and methods like Full Configuration Interaction (FCI) and Coupled Cluster theory, which seek to solve the problem by approximating the total wave function in terms of single-particle basis sets \supercite{daniel_crawford_introduction_2007} As an example, an FCI calculation introduces a series of so-called Slater determinants based on such basis sets. Quantum Monte Carlo (QMC) methods use a different approach and attempt to solve the Schrödinger equation directly using a stochastic evaluation of the integrals \supercite{bajdich_electronic_2010}. What all these methods have in common, is that they require significant amounts of physical intuition in order to work. In general, prior knowledge of the wave function, covering information about the interactions and potential, is required. This knowledge is often unavailable, especially for complex systems, making accurate estimates of the observable unavailable. 

The ultimate goal of this work is to reduce the amount of physical intuition needed by inventing more flexible and sophisticated methods. Machine learning techniques appear as a natural base for these methods, as they can "learn" themselves and thus estimate observables through training processes. The apparent link between machine learning and quantum mechanics are the QMC methods, since they both address to minimize a \textit{cost function} in order to obtain optimal configurations. The connection between machine learning and QMC methods, in particular variational Monte Carlo (VMC), will be discussed thoroughly throughout this work.

\section{Machine learning} \label{sec:machinelearning}
Machine learning has recently achieved immense popularity in fields such as economics \supercite{dube_scalable_2017}, autonomy \supercite{chernova_interactive_2009} - and science, as we will see later, due to its ability to learn without being explicitly programmed. As a branch of artificial intelligence, machine learning is based on studies of the human brain and attempts to recreate the way neurons in the brain process information.

In particular, the artificial neural networks have experienced significant progress over the past decade, which can be attributed to an array of innovations. Most notably, the convolutional neural network (CNN) AlexNet \supercite{krizhevsky_imagenet_2012} managed to increase the top-5 test error rate of image recognition with a remarkable 11.1\% compared to the second-best back in 2012! Today, the CNNs have been further improved, and they are even able to beat humans in recognizing images \supercite{alom_history_2018}. Also, speech recognition algorithms have lately been revolutionized, thanks to recurrent neural networks (RNNs), and especially long short-term memory (LSTM) networks. Their ability to recognize sequential (time-dependent) data has made the technology good enough for entry to millions of people's everyday-life through services such as Google Translate \supercite{wu_googles_2016}, Apple's Siri \supercite{smith_ios_2016} and Amazon Alexa \supercite{noauthor_bringing_nodate}. It is also interesting to see how machine learning has made computers eminent tacticians using reinforcement learning. The DeepMind-developed program AlphaGo demonstrated this by beating the 9-dan professional, Sedol, in the board game Go \supercite{silver2016mastering}. Thereafter, an improved version beat the highest-rated chess computer at that time, Stockfish, in chess \supercite{silver2017mastering}. Both these scenarios were unbelievable just a couple of decades ago.

Admitting that all these branches are both exciting and promising, they will not be discussed further in this work, since they are not relevant to our approach. The reason is that they initially require labeled data in order to be trained, they obey so-called \textit{supervised} learning. For our quantum mechanical systems, we do not have labeled data and therefore need to rely on \textit{unsupervised} learning with the focus on restricted Boltzmann machines (RBMs). Recently, some effort has been put towards this field, known as quantum machine learning. \citet{carleo_solving_2017} demonstrated the link between RBMs and QMC and named the states \textit{neural-network quantum states} (NQS). They used the technique to study the Ising model and the Heisenberg model. \citet{pfau2019abinitio} went further and predicted the dissociation curves of the nitrogen molecule using a so-called fermionic neural network, and \citet{flugsrud_vilde_moe_solving_nodate} investigated ground state properties of circular quantum dots, also using RBMs. We will extend the work she did to larger quantum dots.

\section{Quantum dots}
Quantum dots are often termed artificial atoms because of their common features in comparison to real atoms, where both are made up of electronic structure systems with electrons confined by an external potential. Quantum dots are interesting both from a theoretical, technological and experimental point of view, and are therefore covered in different fields of research. Theoretically, quantum dots are interesting as they are relatively simple structures that can model a long range of phenomena. An example on this is the Wigner localization, which has been observed in strongly interacting quantum dots where the potential energy dominates over the kinetic energy \supercite{ghosal_incipient_2007, hogberget_quantum_2013}. As these systems are more strongly correlated than, for instance, atoms, other challenges are encountered which might require other approaches. Research indicate that quantum Monte Carlo methods are the best suited techniques for studies of these systems \supercite{ghosal_incipient_2007}.

Over the past decade, the popularity of quantum dots has increased, thanks to technological progress in semiconductor research. In particular, they are expected to be the next big thing in display technology due to their ability to emit photons of specific wavelengths, create a smoother transition between different colors and enhance the control of the diodes \supercite{noauthor_samsung_nodate}. The quantum displays have also proven to be 30\% more energy efficient than the current generation of LED displays \supercite{manders_8.3:_2015}, and Samsung already claim that they use this technology in their displays \supercite{noauthor_samsung_nodate}. Another reason why we are interested in simulating quantum dots is because there exist experiments that can be used as benchmarks. Due to very strong confinement in the $z$-direction, the experimental dots, made by patterning GaAs/AlGaAs heterostructures, become essentially two-dimensional \supercite{marzin_photoluminescence_1994,brunner_sharp-line_1994}. For that reason, our main focus in this work is on two-dimensional dots, but also dots of three dimensions will be investigated.

\section{Computer experiments}
The advent of computer technology has offered a new opportunity for studies of quantum (and many other) problems. In addition to the traditional laboratory experiments and analytical approaches, it serves as a third way of doing science which is based on simulations. By the term simulations, we mean reality-based computational models rooted in physical laws, such as the Schrödinger equation. The value behind these models lies in their ability to provide new information or to make predictions which otherwise is too costly or even impossible to obtain. QMC methods illustrates what is the power and potential of such methodologies.

The use and popularity of QMC methods have increased as personal computers and computer clusters have become more powerful. With today's reliable computers, we see these methods as a natural choice when ground state properties of quantum mechanical systems are investigated. Even the most straightforward method, VMC, typically yields excellent results, and the more complicated diffusion Monte Carlo (DMC) is in principle capable of employing exact results. They both appear to have among the highest performance-to-cost ratios out of all the quantum many-body methods. 

Albeit the QMC methods relatively recently have been applied to large-scale calculations, some of the ideas go back to the time before the invention of the electronic computer. Already in the 1940s, Enrico Fermi revealed the similarities between the imaginary time Schrödinger equation and stochastic processes in statistical mechanics\supercite{metropolis_monte_1949,ceperley_quantum_1986}. The first attempt to use this link on actual calculations was performed by a group of scientists at Los Alamos National Laboratory in the early 1950s when they tried to compute the ground state energy of the hydrogen molecule using a simple version of VMC \supercite{bajdich_electronic_2010}. At around the same time, \citet{metropolis_monte_1949} introduced the original Metropolis algorithm, which estimates the energy by moving particles randomly in an ergodic scheme and rejecting inappropriate moves. This method was further improved in the early 1960s when \citet{kalos} laid down the statistical and mathematical framework for Green's functions in QMC methods, and \citet{hastings_monte_1970} developed an efficient algorithm based on the theory, where the particles are moved after the so-called quantum force. The use of the QMC methods on many-fermion systems was first done by \citet{ceperley_quantum_1986} in the 1970-1980s and started a new era of stochastic methods applied to electronic structure problems. 

\section{Ethics in science}
In science, as an entirety, there are some general guidelines that we all should follow in order to maintain ethical behavior. Firstly, one should always have respect for others work, and the authors should be credited whenever one uses others work, no matter the scope. With work, we mean illustrations, text, code, methods, algorithms \textit{et cetera}, which are protected by the Copyright Act (in Norway, åndsverkloven). Secondly, all the research that one does should always be detailed in a such way that others can reproduce the experiments and results. This means that all the factors which possibly have a significant impact on the experiments should be described, and computer experiments are no exceptions. Lastly, there are unfortunately many examples of misuse of knowledge throughout history, something that has to be avoided.

In our specific work, the ethical aspects are also related to the use of machine learning, which can cause fatal consequences if it is not used correctly and carefully. The fact that machine learning allows the computers to learn things themselves have made two of the greatest minds of our time, Stephen Hawking \supercite{cellan-jones_hawking:_2014} and Elon Musk \supercite{vance_elon_2015}, warn us that they can be greatly misused if they are set on learning the wrong things. Every person who develops machine learning algorithms should take this warning seriously, remember that in the end, it is one of us who end up creating the multi-headed monster \textit{Hydra}.

\section{Goals and contributions} \label{sec:goals}
The goals of this work are twofold: First, a flexible software for variational Monte Carlo (VMC) simulations has to be developed. To reduce the required physical intuition, it will support trial wave functions created by restricted Boltzmann machines (RBMs). Also traditional trial wave functions will be implemented used as references. Second, we want to use the developed software to study quantum dots. An important part of this is to provide a thorough comparison of the results obtained by the VMC method with a standard and an RBM trial wave function. We can summarize the goals in five points:
\begin{itemize}
	\item Software development:
	\begin{itemize}
		\item Develop a flexible VMC code.
		\item Implement RBMs as trial wave functions.
	\end{itemize}
	\item Obtaining and analyzing results:
	\begin{itemize}
		\item Study ground state properties of quantum dots and atoms using the VMC method with a standard and an RBM trial wave function.
		\item Experiment with adding selected Jastrow factors to the trial wave function.
		\item Make a critical evaluation of the results obtained when using the various trial wave functions.
	\end{itemize}
\end{itemize}

We believe that machine learning-based methods are the next big thing in many-body quantum mechanics. This work contributes to the rapid developing field of quantum machine learning, as we have investigated one of the many possible approaches. The results are contributions in the sense that we see how good the methods perform, but also the developed software itself is a contribution as it is open-source and can be reused and rewritten by others.

\section{The developed code}
There exists plenty of commercial software programs for solving the quantum many-body problem, and they are often optimized for efficiency. In general, it is wise to use already existing tools and software when doing science. First, this saves time that can be spent on other things. Second, the existing code is usually hard to compete with when it comes to efficiency. However, in our case we will investigate untraditional trial wave functions ansätze which, as far as we know, are not available in existing VMC software. Moreover, we study quantum dots which are not implemented in the most common VMC packages. 

Our VMC solver is written in object-oriented C++, inspired by the example implementation developed by \citet{ledum_simple_2016}, and our single-particle functions are assumed to be given in Cartesian coordinates. The goal is not to compete with the performance of commercial software, but we will still make significant efforts to develop an efficient code. As far as it is possible, all operations are vectorized using the open-source template library Eigen, which again is based on the highly optimized packages BLAS and LAPACK. We used the profiling tool Valgrind to analyze which functions that require most computer power and thus which parts of the code that should be made more efficient. Additionally, the message passing interface (MPI) lets us parallelize the code and thereby run on computer clusters. For implementation details, see chapter \ref{chp:WFE} and \ref{chp:rbmimplementation}. 

The outcome of this work can in its entirety be found on \url{https://github.com/evenmn/}, where the source code is found in the repository \href{https://github.com/evenmn/VMC/tree/master/src}{VMC/src} under the MIT license \supercite{noauthor_mit_nodate}. Python scripts used for less costly operations like plotting, linear regression and symbolic integration are found in the directory \href{https://github.com/evenmn/VMC/tree/master/scripts}{VMC/scripts}, and all the scripts that we refer to throughout the thesis can be found there. We also provide the raw data, including electron density source files, energy expectation value files, files containing final parameters and the raw slurm output files from the Abel computer cluster in Ref. \cite{nordhagen_even_marius_2019_3477946}.

\section{Structure of the thesis}
This thesis is divided into six parts, where each part again is divided into respective chapters. Part \ref{part:quantumtheory} presents the quantum theory, includes an introduction (chapter \ref{chp:quantum}), discussion of many-body quantum mechanics (chapter \ref{chp:manybody}) and detailed about the systems we have investigated (chapter \ref{chp:systems}). Thereafter, the machine learning theory is addressed in Part \ref{part:machinelearningtheory}, where the supervised learning (chapter \ref{chp:machinelearning}) is used as a motivation for the Boltzmann machines (chapter \ref{chp:restricted}). The method is described in Part \ref{part:methods}, and the actual implementation, with focus on efficiency, flexibility and readability, is detailed in Part \ref{part:implementation}. Part \ref{part:results} aims the presentation and discussion of the results, and lastly, we summarize the work and observations in Part \ref{part:conclusion}.

Items that are relevant, but do not belong to the main text are moved to the appendix. This includes derivation of natural units (appendix \ref{app:units}), derivation of a general restricted Boltzmann machine with Gaussian-binary units (appendix \ref{app:rbmderive}) and an extended collection of results (appendix \ref{chp:totalresults}).
