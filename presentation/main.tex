\documentclass{beamer}				% frames
%\documentclass[notes]{beamer}		% frames + notes
%\documentclass[notes=only]{beamer}	% notes
\input{preamble.tex}

\begin{document}

\frontframe

\note{
\begin{itemize}
	\item Glad so many of you could attend this presentation
	\item Present myself
	\item Present topic/master thesis
	\item Practical information (Present a years work in 30 min - leave details in the thesis)
	\item Feel free to ask questions if anything is unclear
\end{itemize}
}

\mframe{Outline}{}{
\begin{itemize}
	\setlength\itemsep{1em}
	\item Motivation
	\item Quantum Theory
	\item Machine Learning Theory
	\item Methods
	\item Results
	\item Conclusion
	\item (Code)
\end{itemize}
}

\note{We will start with some motivation. Thereafter, we present the essential theory, the methods and the results. I will try to spend most of the time on the results. In the end, I will address a brief conclusion, and show how to use the developed software if we have time.}

\titleframe{Motivation}

\mframe{Machine Learning}{Studies of Quantum Dots using \textcolor{red}{\underline{Machine Learning}}}{
	\begin{itemize}
		\setlength\itemsep{3em}
		\item<1-> \begin{shadequote}{}
			Machine learning is the science of getting computers to act without being explicitly programmed \supercite{noauthor_machine_nodate}.
		\end{shadequote}
		\item<2-> Image recognition 
		\item<3-> Voice commands
	\end{itemize}	
}

\note{Split up the title and start with the last term: Machine Learning. This is the method that we use. Machine learning has experienced a booming popularity over the past years. Machine learning algorithms are based on studies of the human brain, and are therefore a branch of artificial intelligence. Neural networks have, for instance, revolutioned the field of image recognition, and they make phones and TVs able to recognize your voice.\bigskip

But this is not related to quantum mechanics, why do we want to use machine learning to solve quantum mechanical problems? Do we use it just because it sounds fancy?}

\mframe{Machine Learning + Quantum Mechanics}{Studies of Quantum Dots using \textcolor{red}{\underline{Machine Learning}}}{
	\begin{itemize}
		\setlength\itemsep{3em}
		\item<1-> Neural networks are eminent function approximators
		\item<2-> Existing methods are reminiscent of machine learning algorithms
	\end{itemize}	
	\pause\pause\vspace{0.6cm}
	\begin{figure}
		\centering
		\input{../tikz/simple_perceptron.tex}
	\end{figure}
}

\note{No, there are some good reasons. Firstly, neural networks have shown impressive power as function approximators. In quantum mechanical calculations, the so-called wave function contains all the information about the system, and is therefore our ultimate goal to find.  By approximating the wave function by a neural network, the network can in principle provide all the desired information. \bigskip

Even though this is a relatively new idea, there exist recent research with the same approach. In 2017, Carlo and Troyer solved the Ising model using restricted Boltzmann machines. A prior student at this group, Flugsrud, extended the work to small quantum dots, and we will again extend her work to larger quantum dots. Recently, \citet{pfau2019abinitio} used more traditional neural networks to study atoms and molecules. }

\mframe{Quantum Dots}{Studies of \textcolor{red}{\underline{Quantum Dots}} using Machine Learning}{
	\begin{itemize}
		\setlength\itemsep{3em}
		\item<1-> \textbf{Technologically:} 
		
		Quantum dots are expected to be the next big thing in display technology \supercite{noauthor_samsung_nodate, manders_8.3:_2015}.
		\item<2-> \textbf{Experimentally:}
		
		Researchers have managed to study two-dimensional quantum dots in the laboratory \supercite{brunner_sharp-line_1994}.
		\item<3-> \textbf{Physically:}
		
		An array of interesting physical phenomena can be observed in quantum dots.
	\end{itemize}
}

\note{We now move back to quantum dots, which is the system we have studied. We could has studied other systems, such as atoms, but quantum dots are exciting for several reasons. 

\vspace{0.5cm}
{\large \textbf{But what are quantum dots?}}

Quantum dots are small artificial particles, often called artificial atoms because of their many common features with atoms. For instance, both quantum dots and atoms have discrete energy spectra. 

\vspace{0.5cm}
{\large \textbf{Why quantum dots?}}

Technologically: Quantum dots are expected to be the next big thing in display technology. They have, for instance, the ability to emit light of specific wave lengths, meaning that the color can be controlled with high precision. Samsung already claim that they use quantum dots in their high-end TVs.}

\note{Experimentally: Quantum dots can be investigated in laboratory experiments. This encourages computational experiments as well, since we can use the results from the laboratory experiments as 		references. Researchers have managed to study quantum dots squeezes between two plates, making the confinement in z-direction absent. This makes them essentially two-dimensional, which is the reason why we have decided to also focus on two-dimensional systems. 
	
	\vspace{0.5cm}
	Physically: From a physical point of view, the quantum dots are interesting as they are simple systems that can model a long range of phenomena. An example is the Wigner localization. 
	
	We will look at circular quantum dots with electron.
}

\iffalse
\mframe{Why quantum dots?}{}{
	\begin{itemize}
		\item \textbf{Technologically:} 
		
			Quantum dots are expected to be the next big thing in display technology \supercite{noauthor_samsung_nodate, manders_8.3:_2015}.
		\item \textbf{Experimentally:}
		
			Researchers have managed to study two-dimensional quantum dots in the laboratory \supercite{brunner_sharp-line_1994}.
		\item \textbf{Physically:}
		
			An array of interesting physical phenomena can be observed in quantum dots.
	\end{itemize}
}

\note{As mentioned initially, we have focused on quantum dots throughout this thesis. 
	
	\vspace{0.5cm}
	{\large \textbf{But what are quantum dots?}}
	
	Quantum dots are small artificial particles, often called artificial atoms because of their many common features with atoms. For instance, both quantum dots and atoms have discrete energy spectra. 
	
	\vspace{0.5cm}
	{\large \textbf{Why quantum dots?}}
	
	Technologically: Quantum dots are expected to be the next big thing in display technology. They have, for instance, the ability to emit light of specific wave lengths, meaning that the color can be controlled with high precision. Samsung already claim that they use quantum dots in their high-end TVs.
	
}
\note{Experimentally: Quantum dots can be investigated in laboratory experiments. This encourages computational experiments as well, since we can use the results from the laboratory experiments as 		references. Researchers have managed to study quantum dots squeezes between two plates, making the confinement in z-direction absent. This makes them essentially two-dimensional, which is the reason why we have decided to also focus on two-dimensional systems. 
	
	\vspace{0.5cm}
	Physically: From a physical point of view, the quantum dots are interesting as they are simple systems that can model a long range of phenomena. An example is the Wigner localization. 
	
	We will look at circular quantum dots with electron.
}
\fi
\iffalse

\mframe{Why is it challenging?}{}{
	\begin{itemize}
		\item Many-body problem
		\item Fermi-Dirac statistics
		\item Hard to compute the wave function
	\end{itemize}
}

\note{The many-body problem is encountered when simulating a quantum many-body system. The problem is caused by the correlations between the particles. A many-body system means more than two particles.
	
	\vspace{0.5cm}
	Fermionic systems need to obey Fermi-Dirac statistics. This results in the requirement of an anti-symmetric wave function under exchange of two particle coordinates. 
	
	\vspace{0.5cm}
	The wave function is categorized as nondeterministic polynomial hard to compute, which means that...
}

\mframe{How to overcome the challenges?}{}{
	\begin{itemize}
		\item Hartree-Fock (HF) theory
		\item Variational Monte Carlo (VMC) method
		\item Our approach: VMC with Machine Learning \supercite{carleo_solving_2017, pfau2019abinitio}
	\end{itemize}
}

\note{There are several different ways to overcome the many-body problem. The Hartree-Fock method is a popular approach, which, loosely speaking, attempts to replace the electron-electron interactions with a mean field. 
	
	\vspace{0.5cm}
	Then we have the variational Monte Carlo method, which attempts to solve the Schrödinger equation accurately using Monte Carlo integration. It is called variational because we need to introduce a trial wave function ansatz, which we vary. Our approach is to let machine learning define this ansatz, inspired by \citet{carleo_solving_2017} and \citet{flugsrud_vilde_moe_solving_nodate}. Also \citet{pfau2019abinitio} has done something similar. 
}	
\fi

\titleframe{Quantum Theory}

\note{I will try to not spend much time on the theory, but there are some necessary parts that need to be covered.}

\mframe{The Schrödinger Equation}{}{
	\begin{empheq}[box={\mybluebox[5pt]}]{equation}
	\hat{\mathcal{H}}\Psi=E\Psi
	\end{empheq}
	\pause
	\vspace{0.2cm}
	\begin{center}
		{\large $\Downarrow$}
	\end{center}
	\vspace{0.3cm}
	\begin{equation}
	E=\frac{\int d\bs{X}\Psi^*(\bs{X})\hat{\mathcal{H}}\Psi(\bs{X})}{\int d\bs{X}\Psi^*(\bs{X})\Psi(\bs{X})}
	\end{equation}
}

\note{The Schrödinger equation describes the motion of any quantum mechanical system, and is the equation that I have spent one year solving. Since we will limit us to stationary systems only, the time-independent Schrödinger equation will be our focus. In linear algebra terms, it is an eigenvalue equation with the Hamilton operator, $\hat{\mathcal{H}}$, as a matrix and the wave function, $\Psi_n$, as the eigen function. $E_n$ is the energy of state $n$, which is the eigenvalue.

\vspace{0.5cm}
The most natural way of solving this equation, is to simply express the Hamiltonian as a matrix and obtain the wave function and the energy from diagonalize the matrix. This is known as configuration interaction. However, we can only do this for small systems, as it is very computational intensive. 
}

\note{Instead, we separate the equation with respect to the energy, and obtain a equation consisting of some integrals. }

\mframe{The Variational Principle}{}{
	
	
	The variational principle serves as a way of finding the ground state energy. For an arbitrary trial wave function $\Psi_T(\bs{X})$, it states that the obtained energy is larger or equal to the ground state,
	\begin{equation}
	E_0\leq E=\frac{\int d\bs{X}\Psi_T^*(\bs{X})\hat{\mathcal{H}}\Psi_T(\bs{X})}{\int d\bs{X}\Psi_T^*(\bs{X})\Psi_T(\bs{X})}.
	\end{equation}
	Thus, by minimizing the obtained energy, $E$, we can estimate the ground state energy. 
}

\titleframe{Machine Learning Theory}

\note{Now over to the machine learning theory.}

\mframe{Feed-forward Neural Network (FNN)}{}{
	\begin{figure}[scale=0.2]
		\centering
		\input{../tikz/multilayer_perceptron_presentation.tex}
	\end{figure}
}

\mframe{Restricted Boltzmann machines}{}{
	\begin{figure}[width=5cm]
		\centering
		\input{../tikz/restricted_boltzmann_machine.tex}
	\end{figure}
}

\titleframe{Methods}

\mframe{Variational Monte Carlo (VMC)}{}{
Exploit the variational principle in order to obtain the ground state energy
	\begin{equation}
	\begin{aligned}
	E_0 < E_{\text{VMC}} &= \frac{\int d\bs{R}\Psi_T(\bs{R})^*\hat{\mathcal{H}}\Psi_T(\bs{R})}{\int d\bs{R}\Psi_T(\bs{R})^*\Psi_T(\bs{R})}\\
	&= \int d\bs{R}\underbrace{\frac{\Psi_T(\bs{R})^*\Psi_T(\bs{R})}{\int d\bs{R}\Psi_T(\bs{R})^*\Psi_T(\bs{R})}}_{P(\bs{R})}\cdot\underbrace{\frac{1}{\Psi_T(\bs{R})}\hat{\mathcal{H}}\Psi_T(\bs{R})}_{E_L(\bs{R})}
	\end{aligned}
	\end{equation}
	
}

\mframe{Monte Carlo Integration}{}{
	We attempt to solve the integral by sampling from the probability density function $P(\bs{R})$
	\begin{equation}
	\begin{aligned}
	E_{\text{VMC}} &= \int d\bs{R} E_L(\bs{R})P(\bs{R}) \\
	&\approx\frac{1}{M}\sum_{i=1}^ME_L(\bs{R}_i)
	\end{aligned}
	\end{equation}
}

\mframe{Trial Wave Function}{}{
	\begin{equation}
	P(\bs{R})\propto\Psi_T(\bs{R})^*\Psi_T(\bs{R})
	\end{equation}
	
	Use the Slater-Jastrow function as our trial wave function
	\begin{equation}
	\Psi_T(\bs{R})=|\hat{D}(\bs{R})|J(\bs{R})
	\end{equation}
	where the Slater matrix, $\hat{D}(\bs{R})$, contains all the single-particle functions
	\begin{equation}
	\hat{D}(\bs{R})=
	\begin{pmatrix}
	\phi_1(\boldsymbol{r}_1) & \phi_2(\boldsymbol{r}_1) & \hdots & \phi_N(\boldsymbol{r}_1)\\
	\phi_1(\boldsymbol{r}_2) & \phi_2(\boldsymbol{r}_2) & \hdots & \phi_N(\boldsymbol{r}_2)\\
	\vdots & \vdots & \ddots & \vdots \\
	\phi_1(\boldsymbol{r}_N) & \phi_2(\boldsymbol{r}_N) & \hdots & \phi_N(\boldsymbol{r}_N)
	\end{pmatrix}
	\end{equation}
}

\mframe{Single-particle Functions}{}{
	The Hermite functions,
	\begin{equation}
	\phi_n(\bs{r})\propto H_n(\bs{r})\exp(-\frac{1}{2}\alpha\omega|\bs{r}|^2),
	\end{equation}
	are used as the single-particle functions for quantum dots in standard VMC. The Gaussian can be factorized out from the Slater determinant.
	\begin{equation}
	|\hat{D}(\bs{R};\alpha)|\propto\exp(-\frac{1}{2}\alpha\omega|\bs{R}|^2)
	\begin{vmatrix}
	H_1(\boldsymbol{r}_1) & H_2(\boldsymbol{r}_1) & \hdots & H_N(\boldsymbol{r}_1)\\
	H_1(\boldsymbol{r}_2) & H_2(\boldsymbol{r}_2) & \hdots & H_N(\boldsymbol{r}_2)\\
	\vdots & \vdots & \ddots & \vdots \\
	H_1(\boldsymbol{r}_N) & H_2(\boldsymbol{r}_N) & \hdots & H_N(\boldsymbol{r}_N)
	\end{vmatrix}
	\end{equation}
}

\mframe{Restricted Boltzmann Machine}{}{
	We use the marginal distribution of the visible units as the single-particle functions in the Slater determinant, and see if them can model the correlations 
	\begin{equation}
	\phi_n(\bs{r})\propto H_n(\bs{r})P(\bs{r};\bs{a},\bs{b},\bs{W})
	\end{equation}
	where $P(\bs{r})$ is the marginal distribution of the visible units.
	\begin{equation}
	|\hat{D}(\bs{r};\bs{a},\bs{b},\bs{W})|\propto P(\bs{r};\bs{a},\bs{b},\bs{W})
	\begin{vmatrix}
	H_1(\boldsymbol{r}_1) & H_2(\boldsymbol{r}_1) & \hdots & H_N(\boldsymbol{r}_1)\\
	H_1(\boldsymbol{r}_2) & H_2(\boldsymbol{r}_2) & \hdots & H_N(\boldsymbol{r}_2)\\
	\vdots & \vdots & \ddots & \vdots \\
	H_1(\boldsymbol{r}_N) & H_2(\boldsymbol{r}_N) & \hdots & H_N(\boldsymbol{r}_N)
	\end{vmatrix}
	\end{equation}
}


\mframe{Jastrow Factor}{}{
The Jastrow factor is added to account for the correlations

Simple Jastrow factor
\begin{equation}
J(\bs{r}; \bs{\beta}) = \exp(\sum_{i=1}^N\sum_{j>i}^N{\beta_{ij}r_{ij}}).
\end{equation}

Padé-Jastrow factor
\begin{equation}
J(\bs{r};\beta) = \exp(\sum_{i=1}^N\sum_{j>i}^N\frac{a_{ij}r_{ij}}{1+\beta r_{ij}}).
\end{equation}
}

\titleframe{Results}

\mframe{Ground State Energy}{Number of electrons: $N=2$. Frequency: $\omega$.}{
\begin{table}
	%\caption{$N=2$}
	\begin{tabularx}{\textwidth}{lR{1.25cm}R{1.25cm}R{1.4cm}R{1.4cm}R{1.2cm}R{1.cm}} 
		\toprule
		$\omega$ & RBM & RBM+SJ & RBM+PJ & VMC & HF \footnote{Computation of the Hartree-Fock limit by \citeauthor{mariadason_quantum_2018}, \citeyear{mariadason_quantum_2018} \cite{mariadason_quantum_2018}.} & Exact \footnote{Semi-analytical ground state energy calculated by \citeauthor{taut_two_1993}, \citeyear{taut_two_1993} \cite{taut_two_1993}.} \\
		\midrule \\
		1/6 & 0.7036(1) & 0.67684(7) & 0.66715(6) & 0.66710(1) & 0.768675 & 2/3 \\ 
		1 & 3.0803(2) & 3.02108(5) & 2.999587(5) & 2.99936(1) & 3.16190 & 3 \\
		\bottomrule
	\end{tabularx}
\end{table}
}

\mframe{Ground State Energy}{Number of electrons: $N=20$. Frequency: $\omega$.}{
\begin{table}
	%\caption{$N=20$}
	\begin{tabularx}{\hsize}{lR{1.25cm}R{1.25cm}R{1.3cm}R{1.4cm}R{1.cm}R{1.4cm}} \\
		\toprule
		$\omega$ & RBM & RBM+SJ & RBM+PJ & VMC & HF \footnote{Computation of the Hartree-Fock limit by \citeauthor{mariadason_quantum_2018}, \citeyear{mariadason_quantum_2018} \cite{mariadason_quantum_2018}.} & DMC \footnote{Ground state energy estimate using the diffusion Monte Carlo method. By \citeauthor{hogberget_quantum_2013}, \citeyear{hogberget_quantum_2013} \cite{hogberget_quantum_2013}.} \\
		\midrule \\
		0.1 & 30.824(2) & 30.567(3) & 30.1553(9) & 30.0403(2) & 31.1902 & 29.9779(1) \\ 
		%0.28 & 63.788(4) & 62.786(3) & 62.148(1) & 63.5390 & 62.0755(7) & 61.9268(1) \\
		%0.5 & 96.410(1) & 94.920(4) & 94.104(1) & 95.7328 & 94.0433(9) & 93.8752(1) \\
		1.0 & 159.428(3) & 156.816(4) & 156.104(1) & 155.8900(4) & 158.004 & 155.8822(1) \\ 
		\bottomrule
	\end{tabularx}
\end{table}
}

\mframe{Energy distribution}{Number of electrons: $N=20$. Frequency: $\omega$.}{
	Ratio between the kinetic energy, $\langle\hat{T}\rangle$, and the total potential energy, $\langle\hat{V}\rangle$.
	\begin{figure}
		\centering 
		\input{../pgf/energy_distribution_20.tex}
		%\caption{$N=20$}
	\end{figure}
}

\mframe{One-body density}{Number of electrons: $N=20$. Frequency: $\omega=1.0$.}{
	\begin{figure}
		\centering
		\captionsetup[subfigure]{labelformat=empty}
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{RBM}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/20P/1.000000w/RBM_ADAM_MC1048576.png}}}\hspace{0.5cm}
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{RBM+SJ}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/20P/1.000000w/RBMSJ_ADAM_MC1048576.png}}}\\
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{RBM+PJ}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/20P/1.000000w/RBMPJ_ADAM_MC1048576.png}}}\hspace{0.5cm}
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{VMC}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/20P/1.000000w/VMC_ADAM_MC1048576.png}}}
		%\caption{$N=20$, $\omega=1.0$}
	\end{figure}
}

\mframe{Two-body density}{Number of electrons: $N=20$. Frequency: $\omega=1.0$.}{
	\begin{figure}
		\centering
		\captionsetup[subfigure]{labelformat=empty}
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{RBM}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/twobody/2D/20P/1.000000w/RBM_ADAM_MC1048576.png}}}\hspace{0.5cm}
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{RBM+SJ}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/twobody/2D/20P/1.000000w/RBMSJ_ADAM_MC1048576.png}}}\\
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{RBM+PJ}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/twobody/2D/20P/1.000000w/RBMPJ_ADAM_MC1048576.png}}}\hspace{0.5cm}
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{VMC}}}\hspace{0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/twobody/2D/20P/1.000000w/VMC_ADAM_MC1048576.png}}}
		%\caption{$N=20$, $\omega=1.0$}
	\end{figure}
}

\mframe{Low-frequency dots}{Number of electrons: $N$. Frequency: $\omega=0.1$.}{
	\begin{figure}
		\centering
		\captionsetup[subfigure]{labelformat=empty}
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{RBM}}}\hspace{0.1cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/2P/0.100000w/RBM_ADAM_MC1048576.png}}}\hspace{-0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/6P/0.100000w/RBM_ADAM_MC1048576.png}}}\hspace{-0.cm}
		\subfloat{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/12P/0.100000w/RBM_ADAM_MC1048576.png}}}\\ [-0.cm]
		
		\subfloat{\raisebox{1cm}{\rotatebox[origin=t]{90}{VMC}}}\hspace{0.1cm}
		\subfloat[$N=2$]{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/2P/0.100000w/VMC_ADAM_MC1048576.png}}}\hspace{-0.cm}
		\subfloat[$N=6$]{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/6P/0.100000w/VMC_ADAM_MC1048576.png}}}\hspace{-0.cm}
		\subfloat[$N=12$]{{\includegraphics[width=3cm]{../plots/int1/onebody2/2D/12P/0.100000w/VMC_ADAM_MC1048576.png}}}
		%\caption{$\omega=0.1$}
	\end{figure}
}

\mframe{Computational Cost}{Number of electrons: $N$.}{
	\begin{figure}
		\centering 
		\input{../pgf/cpu_2D.tex}
	\end{figure} 
}

\titleframe{Conclusion}

\mframe{Conclusions}{}{
	\begin{itemize}
		\item RBM is able to account for most of the correlations
		\item RBM+PJ implies to give a lower ground state energy and model the correlations better than a traditional VMC
		\item RBM+SJ is both more expensive and less accurate than its fellow methods, and we see no reason to choose it
	\end{itemize}
}

\mframe{Future Work}{}{
	\begin{itemize}
		\item Repeat the exercise using spherical coordinates - interactions are easier to model in spherical coordinates
		\item Check the ability of modeling the three-body correlations, considering nuclear systems
		\item Reduce the computational cost
	\end{itemize}
}

\titleframe{Thank you!}

\mframe{References}{}{
	\printbibliography
}

\end{document}